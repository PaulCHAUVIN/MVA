{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["EpaBKWVhB3bu","cYgKI4x8czYu","679xWHHwc5IL","m92FkYzNDs0h","7NjHg-XOH4xn","UROaon2kH-8R","vHFMjj40H7t9","FF_ibWBNbixl","IDQjEN7gbIkD"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["##Part 2\n","#Automatic detection of fraudulous signals using Machine Learning and Deep Learning \n","\n","## MVA Project for the course \"Deep Learning and Signal detection: Introduction and industrial applications\" "],"metadata":{"id":"91_Hr8-AS0Lv"}},{"cell_type":"markdown","source":["# Environment \n"],"metadata":{"id":"tl5V0NQkSyPm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YPrVbGqH12T_"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","from pandas_profiling import ProfileReport\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.stats import kurtosis, skew\n","from scipy.stats.stats import pearsonr  \n","from sklearn.neighbors import KDTree\n","from sklearn.metrics import accuracy_score\n","import json\n","import pickle\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from torch.optim.lr_scheduler import StepLR\n","import torch"]},{"cell_type":"markdown","source":["#data prep"],"metadata":{"id":"sP57lYHAthBz"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BLKIvsIl2CH4","outputId":"0ea6506f-4c16-42e9-c828-f0da46e43738"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["path_to_data = '/content/drive/MyDrive/Projet_II/'"],"metadata":{"id":"VL3k4w3kRfmk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading the labels of the data\n","\n","with open(path_to_data + 'train_labels.json') as f: \n","    dict_labels = json.load(f)\n","\n","with open(path_to_data + '/test_labels.json') as f: \n","    test_labels = json.load(f)"],"metadata":{"id":"MbRy4O5O3uEV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_labels = list(dict_labels.values())\n","list_test_labels = list(test_labels.values())"],"metadata":{"id":"T1v5Gutb3uB1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading into lists different features for the training data and making a DataFrame out of the data\n","\n","trainListBrut = []\n","for i in range(len(dict_labels)):\n","  pdw = np.load(path_to_data + \"train/pdw-\"+str(i)+\".npz\")\n","  element = np.array([pdw['largeur'], pdw['frequence'], pdw['puissance'], pdw['phi'], pdw['theta'], pdw['date']])\n","  trainListBrut.append(element)\n","\n"],"metadata":{"id":"U8dm4GDpIQX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","testListBrut = []\n","for i in range(len(test_labels)):\n","  pdw = np.load(path_to_data + \"test/pdw-\"+str(i)+\".npz\")\n","  element = np.array([pdw['largeur'], pdw['frequence'], pdw['puissance'], pdw['phi'], pdw['theta'], pdw['date']])\n","  testListBrut.append(element)\n","\n","\n"],"metadata":{"id":"0iXybuWEXKnB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","#loading into lists different features for the training data and making a DataFrame out of the data\n","\n","trainListBrutNew = []\n","for i in tqdm(range(len(dict_labels))):\n","  pdw = np.load(path_to_data + \"train/pdw-\"+str(i)+\".npz\")\n","  element = np.array([pdw['largeur'], pdw['frequence'], pdw['puissance'], np.concatenate(([0], np.diff(pdw['date'])))])\n","  trainListBrutNew.append(element)\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZcXNOO0Bcg6B","outputId":"a65be13f-5e3b-4657-ded8-f0c118097acb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2000/2000 [08:36<00:00,  3.87it/s]\n"]}]},{"cell_type":"code","source":["\n","testListBrutNew = []\n","for i in tqdm(range(len(test_labels))):\n","  pdw = np.load(path_to_data + \"test/pdw-\"+str(i)+\".npz\")\n","  element = np.array([pdw['largeur'], pdw['frequence'], pdw['puissance'], np.concatenate(([0], np.diff(pdw['date'])))])\n","  testListBrutNew.append(element)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETBVlgXEhkKk","outputId":"baae5e1d-ff44-4244-913d-d4e6875ca95b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 800/800 [10:39<00:00,  1.25it/s]\n"]}]},{"cell_type":"code","source":["with open('drive/My Drive/Projet_II/trainListBrutNew.pickle', 'wb') as handle:\n","    pickle.dump(trainListBrutNew, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"ZH44uAqNdVKB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('drive/My Drive/Projet_II/trainListBrutNew.pickle', 'rb') as handle:\n","    trainListBrutNew = pickle.load(handle)"],"metadata":{"id":"ZkR8rztPpLD0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('drive/My Drive/Projet_II/testListBrutNew.pickle', 'wb') as handle:\n","    pickle.dump(testListBrutNew, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"mF4IfSVDdY6A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('drive/My Drive/Projet_II/testListBrutNew.pickle', 'rb') as handle:\n","    testListBrutNew = pickle.load(handle)"],"metadata":{"id":"_wBTxJ6spOm4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('drive/My Drive/Projet_II/trainListBrut.pickle', 'wb') as handle:\n","    pickle.dump(trainListBrut, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"g24QbjcBVWOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('drive/My Drive/Projet_II/trainListBrut.pickle', 'rb') as handle:\n","    trainListBrut = pickle.load(handle)"],"metadata":{"id":"MT4uz8T4Wxx5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('drive/My Drive/Projet_II/testListBrut.pickle', 'wb') as handle:\n","    pickle.dump(testListBrut, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"yYJNKPG_XUt5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('drive/My Drive/Projet_II/testListBrut.pickle', 'rb') as handle:\n","    testListBrut = pickle.load(handle)"],"metadata":{"id":"oV-douH8XZsa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading into lists different features for the training data and making a DataFrame out of the data\n","\n","avg_largeurs=[]\n","avg_frequences=[]\n","avg_puissances=[]\n","\n","var_frequences=[]\n","var_puissances=[]\n","\n","kurtosisFreq = []\n","\n","for i in range(len(dict_labels)):\n","  pdw = np.load(\"/content/drive/MyDrive/Projet_II/train/pdw-\"+str(i)+\".npz\")\n","  avg_largeurs.append(np.mean(pdw['largeur']))\n","  avg_frequences.append(np.mean(pdw['frequence']))\n","  avg_puissances.append(np.mean(pdw['puissance']))\n","  var_frequences.append(np.var(pdw['frequence']))\n","  var_puissances.append(np.var(pdw['puissance']))\n","  kurtosisFreq.append(kurtosis(pdw['frequence']))\n","\n","\n"],"metadata":{"id":"CcKq5-_u3t1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","train_completenp = np.column_stack([avg_largeurs, avg_frequences, avg_puissances, var_frequences, var_puissances, kurtosisFreq, list_labels ])\n","train_completeDF = pd.DataFrame(train_completenp, columns=['avg_largeurs', 'avg_frequence', 'avg_puissance', 'var_frequence', 'var_puissance', \"kurtosisFreq\", 'label'])\n","\n","train_completeDF.label = train_completeDF.label.replace('nonmenace', 0)\n","train_completeDF.label = train_completeDF.label.replace('menace', 1)"],"metadata":{"id":"mnUBkilHEZKP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading into lists different features for the testing data and making a DataFrame out of the data\n","Tavg_largeurs=[]\n","Tavg_frequences=[]\n","Tavg_puissances=[]\n","\n","Tvar_frequences=[]\n","Tvar_puissances=[]\n","\n","TkurtosisFreq = []\n","\n","for i in range(len(test_labels)):\n","  pdw = np.load(\"/content/drive/MyDrive/Projet_II/test/pdw-\"+str(i)+\".npz\")\n","  Tavg_largeurs.append(np.mean(pdw['largeur']))\n","  Tavg_frequences.append(np.mean(pdw['frequence']))\n","  Tavg_puissances.append(np.mean(pdw['puissance']))\n","  Tvar_frequences.append(np.var(pdw['frequence']))\n","  Tvar_puissances.append(np.var(pdw['puissance']))\n","  TkurtosisFreq.append(kurtosis(pdw['frequence']))"],"metadata":{"id":"V03JrLSj6Czz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_np = np.column_stack([Tavg_largeurs, Tavg_frequences, Tavg_puissances, Tvar_frequences, Tvar_puissances, TkurtosisFreq, list_test_labels])\n","df_test = pd.DataFrame(test_np, columns=['avg_largeurs', 'avg_frequence', 'avg_puissance', 'var_frequence', \"var_puissances\", 'kurtosisFreq', 'label'])\n","\n","df_test.label = df_test.label.replace('nonmenace', 0)\n","df_test.label = df_test.label.replace('menace', 1)"],"metadata":{"id":"-FJrXPW77Epz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_completeDF\n","#df_test"],"metadata":{"id":"J1UOFX-N8QDc","colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"df28de6e-95ce-4c2e-fdc6-cd1acf0309a0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              avg_largeurs       avg_frequence        avg_puissance  \\\n","0       0.2920029761904762  2.2021488468344814  -151.16828615996047   \n","1      0.13701665124884368  2.9960371178229366  -152.73364850729854   \n","2      0.20196220472440946  0.9864345596615276   -171.2531592449942   \n","3      0.06901390820584145  1.6655921810586563   -149.8297143014817   \n","4       0.3240181518151815  2.2050390746792115  -177.21414360174737   \n","...                    ...                 ...                  ...   \n","1995   0.14399096657633245   1.247535398042877  -184.61802830883272   \n","1996    0.1599614624505929  1.8785500187550042  -147.78948486198558   \n","1997  0.028000492004920056  1.9177639254479806  -148.94320882344323   \n","1998   0.10700590667454227   2.040005034533262  -151.17010967029202   \n","1999   0.22200417246175244  1.8693586683777412  -158.93022397946663   \n","\n","               var_frequence       var_puissance          kurtosisFreq  label  \n","0      7.936452660159338e-05  203.66206708041813   0.49458964678245243      0  \n","1     0.00015197383913408583   135.8561313424652  -0.07343399665103956      0  \n","2     1.6023495255175787e-05   147.9766704169512  0.003984194219526671      1  \n","3      4.368668344947277e-05   91.48433896645852    0.0988434486726617      0  \n","4      7.275157398452599e-05  124.60873001680986  -0.33468901192464795      0  \n","...                      ...                 ...                   ...    ...  \n","1995    0.005022417419248423  174.49384773885774   -1.2253522795829597      1  \n","1996    0.011934391119257374  122.30999316191645   -1.2036825319228355      1  \n","1997  5.8086301056794836e-05  173.90912339106595  -0.13292277449769685      1  \n","1998   6.482565744160364e-05  115.90361023820188  -0.04473800828436403      1  \n","1999   5.551190436372499e-05  121.56249267651124  -0.02307121264511247      0  \n","\n","[2000 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-d97e7be3-559d-47d8-b606-96ba538ce65a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>avg_largeurs</th>\n","      <th>avg_frequence</th>\n","      <th>avg_puissance</th>\n","      <th>var_frequence</th>\n","      <th>var_puissance</th>\n","      <th>kurtosisFreq</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.2920029761904762</td>\n","      <td>2.2021488468344814</td>\n","      <td>-151.16828615996047</td>\n","      <td>7.936452660159338e-05</td>\n","      <td>203.66206708041813</td>\n","      <td>0.49458964678245243</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.13701665124884368</td>\n","      <td>2.9960371178229366</td>\n","      <td>-152.73364850729854</td>\n","      <td>0.00015197383913408583</td>\n","      <td>135.8561313424652</td>\n","      <td>-0.07343399665103956</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.20196220472440946</td>\n","      <td>0.9864345596615276</td>\n","      <td>-171.2531592449942</td>\n","      <td>1.6023495255175787e-05</td>\n","      <td>147.9766704169512</td>\n","      <td>0.003984194219526671</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.06901390820584145</td>\n","      <td>1.6655921810586563</td>\n","      <td>-149.8297143014817</td>\n","      <td>4.368668344947277e-05</td>\n","      <td>91.48433896645852</td>\n","      <td>0.0988434486726617</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.3240181518151815</td>\n","      <td>2.2050390746792115</td>\n","      <td>-177.21414360174737</td>\n","      <td>7.275157398452599e-05</td>\n","      <td>124.60873001680986</td>\n","      <td>-0.33468901192464795</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1995</th>\n","      <td>0.14399096657633245</td>\n","      <td>1.247535398042877</td>\n","      <td>-184.61802830883272</td>\n","      <td>0.005022417419248423</td>\n","      <td>174.49384773885774</td>\n","      <td>-1.2253522795829597</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1996</th>\n","      <td>0.1599614624505929</td>\n","      <td>1.8785500187550042</td>\n","      <td>-147.78948486198558</td>\n","      <td>0.011934391119257374</td>\n","      <td>122.30999316191645</td>\n","      <td>-1.2036825319228355</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1997</th>\n","      <td>0.028000492004920056</td>\n","      <td>1.9177639254479806</td>\n","      <td>-148.94320882344323</td>\n","      <td>5.8086301056794836e-05</td>\n","      <td>173.90912339106595</td>\n","      <td>-0.13292277449769685</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1998</th>\n","      <td>0.10700590667454227</td>\n","      <td>2.040005034533262</td>\n","      <td>-151.17010967029202</td>\n","      <td>6.482565744160364e-05</td>\n","      <td>115.90361023820188</td>\n","      <td>-0.04473800828436403</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1999</th>\n","      <td>0.22200417246175244</td>\n","      <td>1.8693586683777412</td>\n","      <td>-158.93022397946663</td>\n","      <td>5.551190436372499e-05</td>\n","      <td>121.56249267651124</td>\n","      <td>-0.02307121264511247</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2000 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d97e7be3-559d-47d8-b606-96ba538ce65a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d97e7be3-559d-47d8-b606-96ba538ce65a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d97e7be3-559d-47d8-b606-96ba538ce65a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["train_completeDF.to_csv('df_Train.csv')\n","!cp df_Train.csv \"drive/My Drive/Projet_II/\"\n","\n","df_test.to_csv('df_Test.csv')\n","!cp df_Test.csv \"drive/My Drive/Projet_II/\""],"metadata":{"id":"NAd5VuuA8QhI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_completeDF = pd.read_csv('/content/drive/MyDrive/Projet_II/df_Train.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/Projet_II/df_Test.csv')"],"metadata":{"id":"BB8eDUxTBZd1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = train_completeDF.drop(['label'], axis=1).to_numpy()\n","y = np.array(train_completeDF.label)"],"metadata":{"id":"XaWMjB56ABx3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xtest = df_test.drop(['label'], axis=1).to_numpy()\n","ytest = np.array(df_test.label)"],"metadata":{"id":"YoDlUtMkNgXn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Testing ResNet on brute data"],"metadata":{"id":"cYgKI4x8czYu"}},{"cell_type":"markdown","source":["#Prep data for ResNet Brut"],"metadata":{"id":"L1SCeJPYKa0X"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"hQmSGAJRc5UQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_labels = list(dict_labels.values())\n","list_test_labels = list(test_labels.values())"],"metadata":{"id":"D-1iZUy9Wa1i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lastTrain = [torch.from_numpy(item).float() for item in trainListBrut]\n"],"metadata":{"id":"sxIsYB_miz5e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lastTest = [torch.from_numpy(item).float() for item in testListBrut]"],"metadata":{"id":"NcAyk6mAe9n7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["transforming the labels into integers"],"metadata":{"id":"pSFEPeRPdA0c"}},{"cell_type":"code","source":["\n","list_labels = [i.replace('nonmenace', \"0\") for i in list_labels]\n","list_labels = [i.replace('menace', \"1\") for i in list_labels]\n","list_labels  = list(map(int, list_labels ))"],"metadata":{"id":"3UWO0q4BbDAC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_labelsTest = [i.replace('nonmenace', \"0\") for i in list_test_labels]\n","list_labelsTest = [i.replace('menace', \"1\") for i in list_labelsTest]\n","list_labelsTest  = list(map(int, list_labelsTest ))"],"metadata":{"id":"agogmORhfkcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_labels_train_tensor = torch.tensor(list_labels)"],"metadata":{"id":"xL_yJC3naO3W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_labels_test_tensor = torch.tensor(list_labelsTest)"],"metadata":{"id":"98LJz--4fvQ_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Padding the signals with 0"],"metadata":{"id":"679xWHHwc5IL"}},{"cell_type":"code","source":["shapes = [np.shape(x) for x in lastTrain]\n","max_shape = tuple(np.amax(shapes, axis=0))\n"],"metadata":{"id":"fp2vy46QZOfO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hF8P7_Z1ZTFB","outputId":"d249327c-3cdf-4bea-944e-1da641e83810"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6, 20014)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["shapes = [np.shape(x) for x in lastTest]\n","max_shapeTest = tuple(np.amax(shapes, axis=0))\n","max_shapeTest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZZDWJ1rLwnTZ","outputId":"75751eb9-f963-409c-aa39-5c3caed2dcf8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6, 19065)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# desired size\n","size = (6, 20014)\n","\n","# padding value\n","pad_value = 0\n","\n","# list to store padded arrays\n","padded_list_0 = []\n","\n","for array in lastTrain:\n","    # calculate amount of padding needed\n","    pad_width = [(0, size[0]-array.shape[0]), (0, size[1]-array.shape[1])]\n","    # use numpy.pad() to add padding\n","    padded_array = np.pad(array, pad_width, mode='constant', constant_values=pad_value)\n","    padded_list_0.append(padded_array)"],"metadata":{"id":"6rIg9cerZaKs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["padded_list_0[0]"],"metadata":{"id":"RAQphDv8zbo4","outputId":"2b8a7961-ee3d-455f-83dd-f7af3f600f3f","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   0.291     ,    0.291     ,    0.293     , ...,    0.        ,\n","           0.        ,    0.        ],\n","       [   2.2220113 ,    2.1887379 ,    2.2040505 , ...,    0.        ,\n","           0.        ,    0.        ],\n","       [-125.58249   , -133.03972   , -149.99168   , ...,    0.        ,\n","           0.        ,    0.        ],\n","       [   1.6789358 ,    1.8065993 ,    1.380749  , ...,    0.        ,\n","           0.        ,    0.        ],\n","       [   0.957886  ,    0.77572364,    0.8238563 , ...,    0.        ,\n","           0.        ,    0.        ],\n","       [   1.31      ,   24.985     ,   36.823     , ...,    0.        ,\n","           0.        ,    0.        ]], dtype=float32)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["padded_listTest_0 = []\n","\n","for array in lastTest:\n","    # calculate amount of padding needed\n","    pad_width = [(0, size[0]-array.shape[0]), (0, size[1]-array.shape[1])]\n","    # use numpy.pad() to add padding\n","    padded_array = np.pad(array, pad_width, mode='constant', constant_values=pad_value)\n","    padded_listTest_0.append(padded_array)"],"metadata":{"id":"z-i7XT5FfMEZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lastTrain_pad_0 = torch.tensor(padded_list_0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yilmFyjlXXKv","outputId":"14a9e537-4576-418a-802e-70aded21cd0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-130-7ffda439b419>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n","  lastTrain_pad_0 = torch.tensor(padded_list_0)\n"]}]},{"cell_type":"code","source":["lastTest_pad_0 = torch.tensor(padded_listTest_0)\n"],"metadata":{"id":"Gk94peIjffSh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 128"],"metadata":{"id":"pW5XttggWhfk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Padding with -1"],"metadata":{"id":"m92FkYzNDs0h"}},{"cell_type":"code","source":["# desired size\n","size = (6, 20014)\n","\n","# padding value\n","pad_value = -1\n","\n","# list to store padded arrays\n","padded_list_1 = []\n","\n","for array in lastTrain:\n","    # calculate amount of padding needed\n","    pad_width = [(0, size[0]-array.shape[0]), (0, size[1]-array.shape[1])]\n","    # use numpy.pad() to add padding\n","    padded_array = np.pad(array, pad_width, mode='constant', constant_values=pad_value)\n","    padded_list_1.append(padded_array)"],"metadata":{"id":"j2f-PVbVDsYU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["padded_listTest_1 = []\n","\n","for array in lastTest:\n","    # calculate amount of padding needed\n","    pad_width = [(0, size[0]-array.shape[0]), (0, size[1]-array.shape[1])]\n","    # use numpy.pad() to add padding\n","    padded_array = np.pad(array, pad_width, mode='constant', constant_values=pad_value)\n","    padded_listTest_1.append(padded_array)"],"metadata":{"id":"jMbbpI0vDz5r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lastTest_pad_1 = torch.tensor(padded_listTest_1)\n","lastTrain_pad_1 = torch.tensor(padded_list_1)"],"metadata":{"id":"fHIMHxNlD2nV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#data loaders for paddings"],"metadata":{"id":"7NjHg-XOH4xn"}},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","my_datasetTrain_0 = TensorDataset(lastTrain_pad_0,list_labels_train_tensor ) # create your datset\n","my_dataloaderTrain_0 = DataLoader(my_datasetTrain_0, batch_size=batch_size,\n","                                          shuffle=True, drop_last = True)"],"metadata":{"id":"fuyMUEMdkmUr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","my_datasetTest_0 = TensorDataset(lastTest_pad_0,list_labels_test_tensor) # create your datset\n","my_dataloaderTest_0 = DataLoader(my_datasetTest_0, batch_size=batch_size,\n","                                          shuffle=True, drop_last = True)"],"metadata":{"id":"qgyViuRnfzwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","my_datasetTrain_1 = TensorDataset(lastTrain_pad_1,list_labels_train_tensor ) # create your datset\n","my_dataloaderTrain_1 = DataLoader(my_datasetTrain_1, batch_size=batch_size,\n","                                          shuffle=True)\n","\n","my_datasetTest_1 = TensorDataset(lastTest_pad_1,list_labels_test_tensor) # create your datset\n","my_dataloaderTest_1 = DataLoader(my_datasetTest_1, batch_size=batch_size,\n","                                          shuffle=True)\n"],"metadata":{"id":"UirMcj9VEQMO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pooling "],"metadata":{"id":"UROaon2kH-8R"}},{"cell_type":"code","source":["\n","\n","# Create a 1D adaptive max pooling layer\n","adaptive_max_pool = torch.nn.AdaptiveMaxPool1d(output_size=2000)\n","\n","# Apply the pooling layer to the list of signals\n","pooled_signals_Train = [adaptive_max_pool(sig.unsqueeze(0)) for sig in lastTrain]\n","pooled_signals_Test = [adaptive_max_pool(sig.unsqueeze(0)) for sig in lastTest]\n","\n","# The output will be a list of tensors of size (batch_size, num_channels, output_size)"],"metadata":{"id":"GZ23JnA7IBMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_length = max(sig.shape[1] for sig in lastTrain)\n","print(max_length)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THejnTaLR8ta","outputId":"aff26d84-2679-430b-ac7b-bbb682491b3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["20014\n"]}]},{"cell_type":"code","source":["sum = 0\n","for i in lastTrain:\n","  sum += i.shape[1]\n","print(sum/len(lastTrain))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMZo5NN8LsqM","outputId":"5c5cd30b-e541-44e9-b56f-756e8c5fb5e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1698.798\n"]}]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","signals_train_tensor = torch.stack(pooled_signals_Train)\n","\n","\n","my_datasetTrain_pool= TensorDataset(signals_train_tensor, list_labels_train_tensor) # create your datset\n","my_dataloaderTrain_pool = DataLoader(my_datasetTrain_pool, batch_size=batch_size,\n","                                          shuffle=True, drop_last = True)\n","\n","signals_test_tensor = torch.stack(pooled_signals_Test)\n","\n","my_datasetTest_pool = TensorDataset(signals_test_tensor,list_labels_test_tensor) # create your datset\n","my_dataloaderTest_pool = DataLoader(my_datasetTest_pool, batch_size=batch_size,\n","                                          shuffle=True, drop_last = True)"],"metadata":{"id":"S2LHytg0I68U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#The ResNet model "],"metadata":{"id":"vHFMjj40H7t9"}},{"cell_type":"code","source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv1d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n","                        nn.BatchNorm1d(out_channels),\n","                        nn.ReLU())\n","        self.conv2 = nn.Sequential(\n","                        nn.Conv1d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n","                        nn.BatchNorm1d(out_channels))\n","        self.downsample = downsample\n","        self.relu = nn.ReLU()\n","        self.out_channels = out_channels\n","        \n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, layers, num_classes = 1):\n","        super(ResNet, self).__init__()\n","        self.inplanes = 64\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv1d(6, 64, kernel_size = 7, stride = 2, padding = 3),\n","                        nn.BatchNorm1d(64),\n","                        nn.ReLU())\n","        self.maxpool = nn.MaxPool1d(kernel_size = 3, stride = 2, padding = 1)\n","        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n","        #self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n","        #self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n","        #self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n","        self.avgpool = nn.AvgPool1d(7, stride=1)\n","        #self.fc = nn.Linear(in_features=319872, out_features=1, bias=False)\n","        #self.fc = nn.Linear(in_features=26816, out_features=1, bias=False)\n","        self.fc = nn.Linear(in_features=31616, out_features=1, bias=False)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes:\n","            \n","            downsample = nn.Sequential(\n","                nn.Conv1d(self.inplanes, planes, kernel_size=1, stride=stride),\n","                nn.BatchNorm1d(planes),\n","            )\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","    \n","    \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.maxpool(x)\n","        x = self.layer0(x)\n","        #x = self.layer1(x)\n","        # x = self.layer2(x)\n","        # x = self.layer3(x)\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        #x = x.view(-1,x.shape[1]*x.shape[2]) \n","        #print(x.shape)\n","        x = self.fc(x)\n","\n","        return x"],"metadata":{"id":"icwJKoZiVmVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n"],"metadata":{"id":"VMhRlc4UWBKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ResNet(ResidualBlock, [5]).to(device)\n"],"metadata":{"id":"fV5dLxB7Vm3A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sum([element.numel() for element in model.parameters()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tPf1EZjHfAR","outputId":"27eb3e65-2d06-4b17-8616-c2c63d533535"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["159296"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0ImJTAKV-D3","outputId":"2de3208b-0f1e-43c5-d1d5-e45258cd9031"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Sequential(\n","    (0): Conv1d(6, 64, kernel_size=(7,), stride=(2,), padding=(3,))\n","    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer0): Sequential(\n","    (0): ResidualBlock(\n","      (conv1): Sequential(\n","        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","      (conv2): Sequential(\n","        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU()\n","    )\n","    (1): ResidualBlock(\n","      (conv1): Sequential(\n","        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","      (conv2): Sequential(\n","        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU()\n","    )\n","    (2): ResidualBlock(\n","      (conv1): Sequential(\n","        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","      (conv2): Sequential(\n","        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU()\n","    )\n","    (3): ResidualBlock(\n","      (conv1): Sequential(\n","        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","      (conv2): Sequential(\n","        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU()\n","    )\n","    (4): ResidualBlock(\n","      (conv1): Sequential(\n","        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","      (conv2): Sequential(\n","        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU()\n","    )\n","  )\n","  (avgpool): AvgPool1d(kernel_size=(7,), stride=(1,), padding=(0,))\n","  (fc): Linear(in_features=319872, out_features=1, bias=False)\n",")"]},"metadata":{},"execution_count":159}]},{"cell_type":"code","source":["num_epochs = 50\n","learning_rate= 0.0001"],"metadata":{"id":"5tTclSTlg6tU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["55.5% accuracy with padding and resNet with 5 residual blocks 20 epochs\n","\n","\n","65% padding avec adam\n","\n","---\n","\n","\n"],"metadata":{"id":"Q86Xh7KeCQ9B"}},{"cell_type":"markdown","source":["76.75% accuracy avec pooling dim 1698, 90 epochs lr 0.0001, 5 residual blocks \\\\\n","76% for a resnet 15 residual blocks, 150 epochs 0.0001 lr\n","\n","78.125% avec Adam opitimzer"],"metadata":{"id":"w4RFKutKPrSZ"}},{"cell_type":"code","source":["yTrue = []\n","yPred = []\n","\n","from torch.optim.lr_scheduler import StepLR\n","# Loss and optimizer\n","lossFun = torch.nn.BCEWithLogitsLoss()\n","sigmoid = nn.Sigmoid()\n","#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9) \n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","scheduler = StepLR(optimizer, step_size=30, gamma=0.1, verbose=True) \n","\n","# Train the model\n","total_step = len(my_dataloaderTrain_0)\n","\n","acc = []\n","for epoch in range(num_epochs):\n","    for i, (sigs, labels) in enumerate(my_dataloaderTrain_0):  \n","        # Move tensors to the configured device\n","        sigs = sigs.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(sigs.squeeze(1))\n","        # Convert output from sigmoid to binary classes\n","        predicted = (sigmoid(outputs) > 0.5).float()\n","        loss = lossFun(outputs.squeeze(1).float(), labels.float())\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    #scheduler.step()\n","\n","    print ('Epoch [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, loss.item()))\n","            \n","    # Validation\n","\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for sigs, labels in (my_dataloaderTest_0):\n","            sigs = sigs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(sigs.squeeze(1))\n","            predicted = (sigmoid(outputs) > 0.5).int()\n","            total += labels.size(0)\n","            correct += (predicted.squeeze(1) == labels).sum().item()\n","            yTrue.append(labels.int().cpu())\n","            yPred.append(predicted.squeeze(1).cpu())\n","        acc.append(100 * correct / total)\n","        print('Accuracy of the network: {} %'.format(100 * correct / total)) \n","\n","        print('\\n Recall', recall_score(np.array(torch.stack(yTrue, dim=0).cpu()),np.array(torch.stack(yPred, dim=0).cpu()),average='micro'))\n","        print('\\n Precision', precision_score(np.array(torch.stack(yTrue).squeeze(1).cpu()),np.array(torch.stack(yPred).squeeze(1).cpu()),average='micro'))\n","\n","print(\"maximum Accuracy : \", max(acc))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9iuUX0yWChX","outputId":"8d1479ef-8883-4e68-824d-4ca7f8bd3a11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [1/50], Loss: 6.4511\n","Accuracy of the network: 50.520833333333336 %\n","\n"," Recall 0.9216216216216216\n","\n"," Precision 0.49277456647398843\n","Epoch [2/50], Loss: 4.3401\n","Accuracy of the network: 54.557291666666664 %\n","\n"," Recall 0.6576819407008087\n","\n"," Precision 0.5067497403946002\n","Epoch [3/50], Loss: 1.7591\n","Accuracy of the network: 52.864583333333336 %\n","\n"," Recall 0.5899280575539568\n","\n"," Precision 0.5081332300542215\n","Epoch [4/50], Loss: 2.4654\n","Accuracy of the network: 51.432291666666664 %\n","\n"," Recall 0.680349932705249\n","\n"," Precision 0.5055\n","Epoch [5/50], Loss: 1.9340\n","Accuracy of the network: 53.776041666666664 %\n","\n"," Recall 0.5748922413793104\n","\n"," Precision 0.508822126847878\n","Epoch [6/50], Loss: 1.8149\n","Accuracy of the network: 48.828125 %\n","\n"," Recall 0.6286484059272563\n","\n"," Precision 0.5026929982046678\n","Epoch [7/50], Loss: 1.8718\n","Accuracy of the network: 52.473958333333336 %\n","\n"," Recall 0.5714285714285714\n","\n"," Precision 0.5033921302578019\n","Epoch [8/50], Loss: 0.8953\n","Accuracy of the network: 49.869791666666664 %\n","\n"," Recall 0.5705128205128205\n","\n"," Precision 0.5002958579881657\n","Epoch [9/50], Loss: 1.3116\n","Accuracy of the network: 52.734375 %\n","\n"," Recall 0.5241814358666266\n","\n"," Precision 0.5005737234652897\n","Epoch [10/50], Loss: 0.8318\n","Accuracy of the network: 51.5625 %\n","\n"," Recall 0.5112313937753721\n","\n"," Precision 0.49973544973544975\n","Epoch [11/50], Loss: 0.6863\n","Accuracy of the network: 54.296875 %\n","\n"," Recall 0.5043092834277272\n","\n"," Precision 0.5015919666911585\n","Epoch [12/50], Loss: 0.6911\n","Accuracy of the network: 52.864583333333336 %\n","\n"," Recall 0.525152267087751\n","\n"," Precision 0.5024821929635226\n","Epoch [13/50], Loss: 1.4904\n","Accuracy of the network: 53.515625 %\n","\n"," Recall 0.5164651938307628\n","\n"," Precision 0.5031472081218274\n","Epoch [14/50], Loss: 0.8047\n","Accuracy of the network: 51.302083333333336 %\n","\n"," Recall 0.5409170052234474\n","\n"," Precision 0.5025161754133717\n","Epoch [15/50], Loss: 0.7195\n","Accuracy of the network: 52.34375 %\n","\n"," Recall 0.5254512635379062\n","\n"," Precision 0.5028502332008983\n","Epoch [16/50], Loss: 0.8753\n","Accuracy of the network: 52.994791666666664 %\n","\n"," Recall 0.5369774919614148\n","\n"," Precision 0.5032513877874703\n","Epoch [17/50], Loss: 0.5207\n","Accuracy of the network: 55.729166666666664 %\n","\n"," Recall 0.5313047634220169\n","\n"," Precision 0.5052264808362369\n","Epoch [18/50], Loss: 0.5170\n","Accuracy of the network: 51.692708333333336 %\n","\n"," Recall 0.5426379906752895\n","\n"," Precision 0.5048978449482228\n","Epoch [19/50], Loss: 0.9457\n","Accuracy of the network: 55.598958333333336 %\n","\n"," Recall 0.5387243735763098\n","\n"," Precision 0.5069667738478028\n","Epoch [20/50], Loss: 0.6737\n","Accuracy of the network: 51.041666666666664 %\n","\n"," Recall 0.554774141195564\n","\n"," Precision 0.5060449050086355\n","Epoch [21/50], Loss: 0.4983\n","Accuracy of the network: 57.03125 %\n","\n"," Recall 0.5540383872214351\n","\n"," Precision 0.5080921441228589\n","Epoch [22/50], Loss: 0.4786\n","Accuracy of the network: 56.770833333333336 %\n","\n"," Recall 0.5525086079685194\n","\n"," Precision 0.5098729005901044\n","Epoch [23/50], Loss: 0.7297\n","Accuracy of the network: 56.640625 %\n","\n"," Recall 0.5432403812213201\n","\n"," Precision 0.5115222690006648\n","Epoch [24/50], Loss: 0.6646\n","Accuracy of the network: 51.822916666666664 %\n","\n"," Recall 0.5545649475228529\n","\n"," Precision 0.510386373078521\n","Epoch [25/50], Loss: 0.4326\n","Accuracy of the network: 53.90625 %\n","\n"," Recall 0.5650384490414816\n","\n"," Precision 0.5106695379796398\n","Epoch [26/50], Loss: 0.5667\n","Accuracy of the network: 56.25 %\n","\n"," Recall 0.5716963448922212\n","\n"," Precision 0.511744966442953\n","Epoch [27/50], Loss: 0.6391\n","Accuracy of the network: 62.369791666666664 %\n","\n"," Recall 0.573749122631104\n","\n"," Precision 0.5149851498514986\n","Epoch [28/50], Loss: 0.5095\n","Accuracy of the network: 60.286458333333336 %\n","\n"," Recall 0.5725471242145964\n","\n"," Precision 0.5174733531364669\n","Epoch [29/50], Loss: 0.4188\n","Accuracy of the network: 60.286458333333336 %\n","\n"," Recall 0.5746011010543995\n","\n"," Precision 0.5197063043294793\n","Epoch [30/50], Loss: 0.3302\n","Accuracy of the network: 62.369791666666664 %\n","\n"," Recall 0.5774228478613969\n","\n"," Precision 0.5221542227662179\n","Epoch [31/50], Loss: 0.3523\n","Accuracy of the network: 62.109375 %\n","\n"," Recall 0.5729385045422781\n","\n"," Precision 0.52472\n","Epoch [32/50], Loss: 0.3353\n","Accuracy of the network: 60.026041666666664 %\n","\n"," Recall 0.5742934506684718\n","\n"," Precision 0.5264096796711394\n","Epoch [33/50], Loss: 0.4887\n","Accuracy of the network: 63.020833333333336 %\n","\n"," Recall 0.5707485226526592\n","\n"," Precision 0.5290224419931533\n","Epoch [34/50], Loss: 0.2569\n","Accuracy of the network: 61.588541666666664 %\n","\n"," Recall 0.5757527481280866\n","\n"," Precision 0.5307681010427375\n","Epoch [35/50], Loss: 0.3254\n","Accuracy of the network: 62.369791666666664 %\n","\n"," Recall 0.5735738060221379\n","\n"," Precision 0.5328635121530275\n","Epoch [36/50], Loss: 0.3783\n","Accuracy of the network: 59.244791666666664 %\n","\n"," Recall 0.5663856691253951\n","\n"," Precision 0.5343701178809828\n","Epoch [37/50], Loss: 0.6087\n","Accuracy of the network: 62.760416666666664 %\n","\n"," Recall 0.565035886919584\n","\n"," Precision 0.536509040333797\n","Epoch [38/50], Loss: 0.3046\n","Accuracy of the network: 62.239583333333336 %\n","\n"," Recall 0.569594980034227\n","\n"," Precision 0.538057389195743\n","Epoch [39/50], Loss: 0.3078\n","Accuracy of the network: 61.979166666666664 %\n","\n"," Recall 0.5728674631842179\n","\n"," Precision 0.5395838785658205\n","Epoch [40/50], Loss: 0.5362\n","Accuracy of the network: 64.0625 %\n","\n"," Recall 0.5726570964247021\n","\n"," Precision 0.5418375192209124\n","Epoch [41/50], Loss: 0.4567\n","Accuracy of the network: 62.109375 %\n","\n"," Recall 0.577431289640592\n","\n"," Precision 0.542958315214015\n","Epoch [42/50], Loss: 0.3214\n","Accuracy of the network: 61.067708333333336 %\n","\n"," Recall 0.5780544445877951\n","\n"," Precision 0.5440140845070423\n","Epoch [43/50], Loss: 0.2978\n","Accuracy of the network: 65.49479166666667 %\n","\n"," Recall 0.5795010709336021\n","\n"," Precision 0.5462264711121667\n","Epoch [44/50], Loss: 0.2817\n","Accuracy of the network: 62.630208333333336 %\n","\n"," Recall 0.5793005787464598\n","\n"," Precision 0.5476717112922003\n","Epoch [45/50], Loss: 0.3779\n","Accuracy of the network: 60.026041666666664 %\n","\n"," Recall 0.5833935452793835\n","\n"," Precision 0.5479893671172446\n","Epoch [46/50], Loss: 0.5059\n","Accuracy of the network: 60.286458333333336 %\n","\n"," Recall 0.5883357879234168\n","\n"," Precision 0.5482843810046665\n","Epoch [47/50], Loss: 0.2424\n","Accuracy of the network: 60.546875 %\n","\n"," Recall 0.5892187950417987\n","\n"," Precision 0.54904910282583\n","Epoch [48/50], Loss: 0.3005\n","Accuracy of the network: 58.59375 %\n","\n"," Recall 0.5908218559494243\n","\n"," Precision 0.5493046444502755\n","Epoch [49/50], Loss: 0.2075\n","Accuracy of the network: 64.71354166666667 %\n","\n"," Recall 0.5899463584582204\n","\n"," Precision 0.5510045968699964\n","Epoch [50/50], Loss: 0.3326\n","Accuracy of the network: 62.5 %\n","\n"," Recall 0.5901701528123984\n","\n"," Precision 0.5521699452443724\n","maximum Accuracy :  65.49479166666667\n"]}]},{"cell_type":"markdown","source":["#Testing processed signals (Stat values) with a ResNet"],"metadata":{"id":"FF_ibWBNbixl"}},{"cell_type":"code","source":["x = torch.from_numpy(x)\n","y = torch.from_numpy(y)\n","\n","xtest = torch.from_numpy(xtest)\n","ytest = torch.from_numpy(ytest)"],"metadata":{"id":"Vdb1LGWbav3w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 36"],"metadata":{"id":"FmE5z3w_bRXq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_datasetTrain = TensorDataset(x,y) # create your datset\n","my_dataloaderTrain = DataLoader(my_datasetTrain, batch_size=batch_size,\n","                                          shuffle=True, drop_last = True)"],"metadata":{"id":"NA8tOu_2b3NB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_datasetTest = TensorDataset(xtest,ytest) # create your datset\n","my_dataloaderTest = DataLoader(my_datasetTest, batch_size=batch_size,\n","                                          shuffle=True, drop_last = True)"],"metadata":{"id":"d0wEkt6ycHeW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv1d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n","                        nn.BatchNorm1d(out_channels),\n","                        nn.ReLU())\n","        self.conv2 = nn.Sequential(\n","                        nn.Conv1d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n","                        nn.BatchNorm1d(out_channels))\n","        self.downsample = downsample\n","        self.relu = nn.ReLU()\n","        self.out_channels = out_channels\n","        \n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, layers, num_classes = 1):\n","        super(ResNet, self).__init__()\n","        self.inplanes = 64\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv1d(1, 64, kernel_size = 7, stride = 2, padding = 3),\n","                        nn.BatchNorm1d(64),\n","                        nn.ReLU())\n","        self.maxpool = nn.MaxPool1d(kernel_size = 3, stride = 2, padding = 1)\n","        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n","        #self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n","        #self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n","        #self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n","        self.avgpool = nn.AvgPool1d(1, stride=1)\n","        #self.fc = nn.Linear(in_features=319872, out_features=1, bias=False)\n","        #self.fc = nn.Linear(in_features=26816, out_features=1, bias=False)\n","        #self.fc = nn.Linear(in_features=31616, out_features=1, bias=False)\n","        self.fc = nn.Linear(in_features=128, out_features=1, bias=False)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes:\n","            \n","            downsample = nn.Sequential(\n","                nn.Conv1d(self.inplanes, planes, kernel_size=1, stride=stride),\n","                nn.BatchNorm1d(planes),\n","            )\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","    \n","    \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.maxpool(x)\n","        x = self.layer0(x)\n","        #x = self.layer1(x)\n","        # x = self.layer2(x)\n","        # x = self.layer3(x)\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        #x = x.view(-1,x.shape[1]*x.shape[2]) \n","        #print(x.shape)\n","        x = self.fc(x)\n","\n","        return x\n","\n","\n","\n","\n"],"metadata":{"id":"mlnqywcWbaP-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ResNet(ResidualBlock, [5]).to(device)"],"metadata":{"id":"9Vu5O-X1d-Bi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list1 = [element.numel() for element in model.parameters()]\n","summ = 0\n","for i in list1:\n","  summ += i\n","summ"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ut2QMamwA0i5","outputId":"453f7da9-e0a3-4cd9-b7e5-4f5ad61c7032"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["125568"]},"metadata":{},"execution_count":193}]},{"cell_type":"code","source":["num_epochs = 300\n","learning_rate= 0.01"],"metadata":{"id":"cWd1VqD5dZjU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["66.875% with 150 epochs, 5 resblocks \\\\\n","79.375% 300 epochs \n","\n","83.125% 300 epochs Adam optimizer"],"metadata":{"id":"mVgkHV-4d2Me"}},{"cell_type":"code","source":["from sklearn.metrics import recall_score, precision_score\n","yTrue = []\n","yPred =[]\n","# Loss and optimizer\n","lossFun = torch.nn.BCEWithLogitsLoss()\n","sigmoid = nn.Sigmoid()\n","#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9) \n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay = 0.0001)\n","\n","scheduler = StepLR(optimizer, step_size=100, gamma=0.1, verbose=True) \n","\n","# Train the model\n","total_step = len(my_dataloaderTrain)\n","\n","acc = []\n","for epoch in range(num_epochs):\n","    for i, (sigs, labels) in enumerate(my_dataloaderTrain):  \n","        # Move tensors to the configured device\n","        sigs = sigs.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(sigs.unsqueeze(1).float())\n","        # Convert output from sigmoid to binary classes\n","        predicted = (sigmoid(outputs) > 0.5).float()\n","        loss = lossFun(outputs.squeeze(1).float(), labels.float())\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    scheduler.step()\n","\n","    print ('Epoch [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, loss.item()))\n","            \n","    # Validation\n","\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for sigs, labels in (my_dataloaderTest):\n","            sigs = sigs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(sigs.unsqueeze(1).float())\n","            predicted = (sigmoid(outputs) > 0.5).int()\n","            total += labels.size(0)\n","            correct += (predicted.squeeze(1) == labels).sum().item()\n","            yTrue.append(labels.int().cpu())\n","            #print(\"labels\", labels.shape)\n","            #print(\"predicted\", predicted.squeeze(1).shape)\n","            yPred.append(predicted.squeeze(1).cpu())\n","        acc.append(100 * correct / total)\n","        print('Accuracy of the network: {} %'.format(100 * correct / total))\n","        #print(np.array(torch.stack(yTrue, dim=0).cpu()))\n","\n","        print('\\n Recall', recall_score(np.array(torch.stack(yTrue, dim=0).cpu()),np.array(torch.stack(yPred, dim=0).cpu()),average='micro'))\n","        print('\\n Precision', precision_score(np.array(torch.stack(yTrue).squeeze(1).cpu()),np.array(torch.stack(yPred).squeeze(1).cpu()),average='micro'))\n","\n","print(\"maximum Accuracy : \", max(acc))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQUuz51db8Gv","outputId":"b693ca0c-8fbe-4f2e-8538-83540547beb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0000e-02.\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [1/300], Loss: 0.6764\n","Accuracy of the network: 52.27272727272727 %\n","\n"," Recall 0.5380577427821522\n","\n"," Precision 0.5036855036855037\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [2/300], Loss: 0.7508\n","Accuracy of the network: 50.63131313131313 %\n","\n"," Recall 0.6259842519685039\n","\n"," Precision 0.4963579604578564\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [3/300], Loss: 0.6871\n","Accuracy of the network: 58.71212121212121 %\n","\n"," Recall 0.4645048203330412\n","\n"," Precision 0.5221674876847291\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [4/300], Loss: 0.6549\n","Accuracy of the network: 57.323232323232325 %\n","\n"," Recall 0.4174884944115713\n","\n"," Precision 0.536770921386306\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [5/300], Loss: 0.6212\n","Accuracy of the network: 61.48989898989899 %\n","\n"," Recall 0.3742105263157895\n","\n"," Precision 0.5638382236320381\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [6/300], Loss: 0.5406\n","Accuracy of the network: 61.61616161616162 %\n","\n"," Recall 0.346035917652212\n","\n"," Precision 0.5895522388059702\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [7/300], Loss: 0.6169\n","Accuracy of the network: 58.83838383838384 %\n","\n"," Recall 0.37265214124718254\n","\n"," Precision 0.5866351271437019\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [8/300], Loss: 0.5965\n","Accuracy of the network: 63.005050505050505 %\n","\n"," Recall 0.3844889911271771\n","\n"," Precision 0.5972434915773354\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [9/300], Loss: 0.6918\n","Accuracy of the network: 62.5 %\n","\n"," Recall 0.3792700729927007\n","\n"," Precision 0.6092870544090057\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [10/300], Loss: 0.5412\n","Accuracy of the network: 62.878787878787875 %\n","\n"," Recall 0.3919558359621451\n","\n"," Precision 0.6133278486219663\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [11/300], Loss: 0.5416\n","Accuracy of the network: 64.8989898989899 %\n","\n"," Recall 0.4171647143198661\n","\n"," Precision 0.6148696264975335\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [12/300], Loss: 0.6625\n","Accuracy of the network: 62.37373737373738 %\n","\n"," Recall 0.4084136722173532\n","\n"," Precision 0.6227865018376211\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [13/300], Loss: 0.5092\n","Accuracy of the network: 73.48484848484848 %\n","\n"," Recall 0.4290916447501517\n","\n"," Precision 0.6354104254044338\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [14/300], Loss: 0.4363\n","Accuracy of the network: 77.27272727272727 %\n","\n"," Recall 0.43799323562570464\n","\n"," Precision 0.6549592582186007\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [15/300], Loss: 0.4674\n","Accuracy of the network: 78.53535353535354 %\n","\n"," Recall 0.4501929147667485\n","\n"," Precision 0.6718136613451976\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [16/300], Loss: 0.3694\n","Accuracy of the network: 76.51515151515152 %\n","\n"," Recall 0.46128554989314485\n","\n"," Precision 0.6837231968810916\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [17/300], Loss: 0.4822\n","Accuracy of the network: 77.3989898989899 %\n","\n"," Recall 0.4750928217821782\n","\n"," Precision 0.6929151624548736\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [18/300], Loss: 0.3078\n","Accuracy of the network: 78.66161616161617 %\n","\n"," Recall 0.4897750511247444\n","\n"," Precision 0.7010244616349571\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [19/300], Loss: 0.4642\n","Accuracy of the network: 77.14646464646465 %\n","\n"," Recall 0.49508786495087864\n","\n"," Precision 0.7109080071527916\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [20/300], Loss: 0.5396\n","Accuracy of the network: 79.29292929292929 %\n","\n"," Recall 0.5074254172690236\n","\n"," Precision 0.7175246236758966\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [21/300], Loss: 0.3140\n","Accuracy of the network: 78.28282828282828 %\n","\n"," Recall 0.5114532482162975\n","\n"," Precision 0.7266583674195269\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [22/300], Loss: 0.4815\n","Accuracy of the network: 79.04040404040404 %\n","\n"," Recall 0.5226430875851357\n","\n"," Precision 0.7308270676691729\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [23/300], Loss: 0.3865\n","Accuracy of the network: 77.3989898989899 %\n","\n"," Recall 0.5356571428571428\n","\n"," Precision 0.73131533780621\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [24/300], Loss: 0.3554\n","Accuracy of the network: 79.67171717171718 %\n","\n"," Recall 0.5437616387337058\n","\n"," Precision 0.7359525574499629\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [25/300], Loss: 0.4559\n","Accuracy of the network: 79.29292929292929 %\n","\n"," Recall 0.5525181368941225\n","\n"," Precision 0.7392038261358841\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [26/300], Loss: 0.3522\n","Accuracy of the network: 79.92424242424242 %\n","\n"," Recall 0.5605095541401274\n","\n"," Precision 0.7425663005625502\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [27/300], Loss: 0.3428\n","Accuracy of the network: 78.78787878787878 %\n","\n"," Recall 0.5694119937694704\n","\n"," Precision 0.7438636652677095\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [28/300], Loss: 0.3683\n","Accuracy of the network: 79.92424242424242 %\n","\n"," Recall 0.5771144278606966\n","\n"," Precision 0.7462070639640733\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [29/300], Loss: 0.3627\n","Accuracy of the network: 80.3030303030303 %\n","\n"," Recall 0.581694608065247\n","\n"," Precision 0.7503214494447692\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [30/300], Loss: 0.5054\n","Accuracy of the network: 80.3030303030303 %\n","\n"," Recall 0.5873335669236159\n","\n"," Precision 0.7532015277465738\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [31/300], Loss: 0.4594\n","Accuracy of the network: 78.53535353535354 %\n","\n"," Recall 0.5937950326354158\n","\n"," Precision 0.753955440749112\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [32/300], Loss: 0.5726\n","Accuracy of the network: 79.54545454545455 %\n","\n"," Recall 0.5994416160289046\n","\n"," Precision 0.7555371558683502\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [33/300], Loss: 0.4660\n","Accuracy of the network: 79.04040404040404 %\n","\n"," Recall 0.6061474757126931\n","\n"," Precision 0.755758538522637\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [34/300], Loss: 0.3167\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.6082386583198083\n","\n"," Precision 0.7598725499662065\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [35/300], Loss: 0.2890\n","Accuracy of the network: 77.9040404040404 %\n","\n"," Recall 0.6128378378378379\n","\n"," Precision 0.760268231349539\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [36/300], Loss: 0.3665\n","Accuracy of the network: 80.68181818181819 %\n","\n"," Recall 0.6166812609457093\n","\n"," Precision 0.7625879805089334\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [37/300], Loss: 0.4320\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.620927095904025\n","\n"," Precision 0.7644642545009613\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [38/300], Loss: 0.3275\n","Accuracy of the network: 77.9040404040404 %\n","\n"," Recall 0.6257257395631739\n","\n"," Precision 0.7640952059419311\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [39/300], Loss: 0.4399\n","Accuracy of the network: 80.55555555555556 %\n","\n"," Recall 0.6283924843423799\n","\n"," Precision 0.7662806931099614\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [40/300], Loss: 0.3142\n","Accuracy of the network: 78.91414141414141 %\n","\n"," Recall 0.6326329612606697\n","\n"," Precision 0.7664465834062525\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [41/300], Loss: 0.3620\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.6357463164638053\n","\n"," Precision 0.7678737233054782\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [42/300], Loss: 0.3345\n","Accuracy of the network: 78.78787878787878 %\n","\n"," Recall 0.63910949909324\n","\n"," Precision 0.7682477636623318\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [43/300], Loss: 0.4652\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.6416661576986502\n","\n"," Precision 0.7699523635031147\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [44/300], Loss: 0.3035\n","Accuracy of the network: 79.41919191919192 %\n","\n"," Recall 0.6437268711949385\n","\n"," Precision 0.7711834107972828\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [45/300], Loss: 0.4120\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.6463208262823131\n","\n"," Precision 0.772438803263826\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [46/300], Loss: 0.2176\n","Accuracy of the network: 81.31313131313131 %\n","\n"," Recall 0.6497117086259062\n","\n"," Precision 0.7733233675341442\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [47/300], Loss: 0.4853\n","Accuracy of the network: 78.91414141414141 %\n","\n"," Recall 0.6527568292274175\n","\n"," Precision 0.7734312946783162\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [48/300], Loss: 0.3426\n","Accuracy of the network: 78.66161616161617 %\n","\n"," Recall 0.6559457389782299\n","\n"," Precision 0.7731785944551902\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [49/300], Loss: 0.4263\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.6589508653485506\n","\n"," Precision 0.7737997860693387\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [50/300], Loss: 0.3642\n","Accuracy of the network: 80.17676767676768 %\n","\n"," Recall 0.6621855800031508\n","\n"," Precision 0.7739045047256659\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [51/300], Loss: 0.4075\n","Accuracy of the network: 79.67171717171718 %\n","\n"," Recall 0.6649160745546288\n","\n"," Precision 0.7740350035962599\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [52/300], Loss: 0.3617\n","Accuracy of the network: 79.04040404040404 %\n","\n"," Recall 0.6684173315826685\n","\n"," Precision 0.7734018931868646\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [53/300], Loss: 0.4438\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.6695402298850575\n","\n"," Precision 0.7749297551465107\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [54/300], Loss: 0.3888\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.6711396343835083\n","\n"," Precision 0.7759415401911186\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [55/300], Loss: 0.2434\n","Accuracy of the network: 79.67171717171718 %\n","\n"," Recall 0.6728088600343708\n","\n"," Precision 0.7764861440141039\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [56/300], Loss: 0.3829\n","Accuracy of the network: 77.65151515151516 %\n","\n"," Recall 0.6751687921980495\n","\n"," Precision 0.7758620689655172\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [57/300], Loss: 0.4395\n","Accuracy of the network: 79.92424242424242 %\n","\n"," Recall 0.6766020177822822\n","\n"," Precision 0.7765147509781114\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [58/300], Loss: 0.2649\n","Accuracy of the network: 80.55555555555556 %\n","\n"," Recall 0.678391959798995\n","\n"," Precision 0.7771496732704076\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [59/300], Loss: 0.4247\n","Accuracy of the network: 80.55555555555556 %\n","\n"," Recall 0.6809239807726545\n","\n"," Precision 0.7771907543815088\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [60/300], Loss: 0.3692\n","Accuracy of the network: 80.05050505050505 %\n","\n"," Recall 0.6829182896406845\n","\n"," Precision 0.7774013551215624\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [61/300], Loss: 0.3509\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.6846024708363824\n","\n"," Precision 0.7778919051112742\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [62/300], Loss: 0.3016\n","Accuracy of the network: 78.78787878787878 %\n","\n"," Recall 0.6865867604082843\n","\n"," Precision 0.7776178826689691\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [63/300], Loss: 0.2546\n","Accuracy of the network: 79.79797979797979 %\n","\n"," Recall 0.6884507981494603\n","\n"," Precision 0.7777202316493244\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [64/300], Loss: 0.4672\n","Accuracy of the network: 79.79797979797979 %\n","\n"," Recall 0.6899154837121523\n","\n"," Precision 0.7780142500231332\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [65/300], Loss: 0.3261\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.690729145627146\n","\n"," Precision 0.7791397065524469\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [66/300], Loss: 0.3699\n","Accuracy of the network: 78.91414141414141 %\n","\n"," Recall 0.6927514322087842\n","\n"," Precision 0.7787567084078711\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [67/300], Loss: 0.3811\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.6939383253007327\n","\n"," Precision 0.7793522267206477\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [68/300], Loss: 0.4088\n","Accuracy of the network: 81.31313131313131 %\n","\n"," Recall 0.6947071767748909\n","\n"," Precision 0.7803555941023417\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [69/300], Loss: 0.3244\n","Accuracy of the network: 79.41919191919192 %\n","\n"," Recall 0.6963171511185512\n","\n"," Precision 0.7802694406548432\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [70/300], Loss: 0.3345\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.6972662841714479\n","\n"," Precision 0.7811948575749937\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [71/300], Loss: 0.3104\n","Accuracy of the network: 79.67171717171718 %\n","\n"," Recall 0.6983915696062118\n","\n"," Precision 0.781367641583585\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [72/300], Loss: 0.2775\n","Accuracy of the network: 80.05050505050505 %\n","\n"," Recall 0.6990337283500456\n","\n"," Precision 0.7819472202961211\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [73/300], Loss: 0.3833\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.6997662290954865\n","\n"," Precision 0.7826943963956716\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [74/300], Loss: 0.3548\n","Accuracy of the network: 79.92424242424242 %\n","\n"," Recall 0.7009296054499007\n","\n"," Precision 0.7828412918565485\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [75/300], Loss: 0.3826\n","Accuracy of the network: 80.3030303030303 %\n","\n"," Recall 0.7015228426395939\n","\n"," Precision 0.7834467120181405\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [76/300], Loss: 0.4494\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.7027914046845851\n","\n"," Precision 0.7837192279539238\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [77/300], Loss: 0.6078\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7035496300337573\n","\n"," Precision 0.7843755939935374\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [78/300], Loss: 0.5264\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.704419238665814\n","\n"," Precision 0.7849159915991599\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [79/300], Loss: 0.3247\n","Accuracy of the network: 79.92424242424242 %\n","\n"," Recall 0.7053604067661428\n","\n"," Precision 0.7850933974477529\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [80/300], Loss: 0.5832\n","Accuracy of the network: 78.78787878787878 %\n","\n"," Recall 0.7065406452036362\n","\n"," Precision 0.7848419671174948\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [81/300], Loss: 0.4652\n","Accuracy of the network: 80.17676767676768 %\n","\n"," Recall 0.7071826785945806\n","\n"," Precision 0.7852438366024833\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [82/300], Loss: 0.3462\n","Accuracy of the network: 80.05050505050505 %\n","\n"," Recall 0.7079371177920789\n","\n"," Precision 0.7855265027710672\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [83/300], Loss: 0.3277\n","Accuracy of the network: 79.04040404040404 %\n","\n"," Recall 0.7089580565572214\n","\n"," Precision 0.7854014086974804\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [84/300], Loss: 0.2740\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.7094364392210796\n","\n"," Precision 0.7862066576604663\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [85/300], Loss: 0.3371\n","Accuracy of the network: 80.68181818181819 %\n","\n"," Recall 0.7101158301158301\n","\n"," Precision 0.7866283446246493\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [86/300], Loss: 0.4480\n","Accuracy of the network: 79.16666666666667 %\n","\n"," Recall 0.7102170395921732\n","\n"," Precision 0.7871037585845259\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [87/300], Loss: 0.3079\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7111345805672903\n","\n"," Precision 0.7874302515954426\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [88/300], Loss: 0.5594\n","Accuracy of the network: 79.67171717171718 %\n","\n"," Recall 0.7122016706443914\n","\n"," Precision 0.7873161400962997\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [89/300], Loss: 0.4353\n","Accuracy of the network: 79.79797979797979 %\n","\n"," Recall 0.7130552769748097\n","\n"," Precision 0.7873754152823921\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [90/300], Loss: 0.2679\n","Accuracy of the network: 79.92424242424242 %\n","\n"," Recall 0.7132814095271434\n","\n"," Precision 0.7878084928152587\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [91/300], Loss: 0.2874\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.713700487551568\n","\n"," Precision 0.7883935115841805\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [92/300], Loss: 0.3982\n","Accuracy of the network: 80.17676767676768 %\n","\n"," Recall 0.7144569373894184\n","\n"," Precision 0.7885105980913987\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [93/300], Loss: 0.3054\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7146849593495935\n","\n"," Precision 0.7892324957915082\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [94/300], Loss: 0.3413\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.7152193950227634\n","\n"," Precision 0.789584039961765\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [95/300], Loss: 0.3201\n","Accuracy of the network: 79.41919191919192 %\n","\n"," Recall 0.7153042613165312\n","\n"," Precision 0.789989317869678\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [96/300], Loss: 0.4536\n","Accuracy of the network: 79.16666666666667 %\n","\n"," Recall 0.715918724533049\n","\n"," Precision 0.7899755575002263\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [97/300], Loss: 0.4094\n","Accuracy of the network: 79.29292929292929 %\n","\n"," Recall 0.7165746454476561\n","\n"," Precision 0.7899510681465569\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [98/300], Loss: 0.3618\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.7163483432000214\n","\n"," Precision 0.7907155529272619\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [99/300], Loss: 0.4394\n","Accuracy of the network: 80.05050505050505 %\n","\n"," Recall 0.7165773983136235\n","\n"," Precision 0.791106817716109\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [100/300], Loss: 0.2740\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.7167007927757653\n","\n"," Precision 0.7917065390749601\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [101/300], Loss: 0.2857\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.7170110461338531\n","\n"," Precision 0.7921608040201005\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [102/300], Loss: 0.4640\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.7172380070002059\n","\n"," Precision 0.7926336746302617\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [103/300], Loss: 0.3724\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.717620673836587\n","\n"," Precision 0.7931830985915493\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [104/300], Loss: 0.3452\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.7179849578516986\n","\n"," Precision 0.7937057083868088\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [105/300], Loss: 0.3363\n","Accuracy of the network: 80.68181818181819 %\n","\n"," Recall 0.7180711446641502\n","\n"," Precision 0.7942103516921035\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [106/300], Loss: 0.3666\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.7181309429477021\n","\n"," Precision 0.7946785773003782\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [107/300], Loss: 0.2866\n","Accuracy of the network: 80.17676767676768 %\n","\n"," Recall 0.7182072416838386\n","\n"," Precision 0.7950737310919805\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [108/300], Loss: 0.3601\n","Accuracy of the network: 80.55555555555556 %\n","\n"," Recall 0.7182229135274388\n","\n"," Precision 0.7955848701036479\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [109/300], Loss: 0.4121\n","Accuracy of the network: 80.68181818181819 %\n","\n"," Recall 0.718238297052591\n","\n"," Precision 0.7961084716809907\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [110/300], Loss: 0.2434\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7182876777703541\n","\n"," Precision 0.7966653433902342\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [111/300], Loss: 0.3657\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.7183901250916314\n","\n"," Precision 0.7971242653232578\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [112/300], Loss: 0.3541\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7183838005062342\n","\n"," Precision 0.7977305850510098\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [113/300], Loss: 0.2950\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.718397212543554\n","\n"," Precision 0.7982397274416684\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [114/300], Loss: 0.3711\n","Accuracy of the network: 82.07070707070707 %\n","\n"," Recall 0.718466497812572\n","\n"," Precision 0.7988888319934456\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [115/300], Loss: 0.4186\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7183648315529991\n","\n"," Precision 0.799517337736568\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [116/300], Loss: 0.3077\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.7181680356617564\n","\n"," Precision 0.8002521432173475\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [117/300], Loss: 0.2852\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.7181765154574415\n","\n"," Precision 0.8008806384628856\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [118/300], Loss: 0.2702\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7180958736514292\n","\n"," Precision 0.8014996151649825\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [119/300], Loss: 0.3504\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.7179408002117429\n","\n"," Precision 0.8021192705766388\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [120/300], Loss: 0.2736\n","Accuracy of the network: 80.3030303030303 %\n","\n"," Recall 0.7180979045452557\n","\n"," Precision 0.8023755987877603\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [121/300], Loss: 0.3223\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.7179704108638119\n","\n"," Precision 0.802915989422867\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [122/300], Loss: 0.3299\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.7179740952708809\n","\n"," Precision 0.8035155309414881\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [123/300], Loss: 0.2694\n","Accuracy of the network: 80.17676767676768 %\n","\n"," Recall 0.7178403755868544\n","\n"," Precision 0.803948280394828\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [124/300], Loss: 0.2960\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7177815410668925\n","\n"," Precision 0.8044984340893993\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [125/300], Loss: 0.2516\n","Accuracy of the network: 80.55555555555556 %\n","\n"," Recall 0.717609508210491\n","\n"," Precision 0.8050032978422689\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [126/300], Loss: 0.3816\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.717678430065414\n","\n"," Precision 0.8055276264409474\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [127/300], Loss: 0.3160\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.7177462692736968\n","\n"," Precision 0.8060255785344568\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [128/300], Loss: 0.2482\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.7176752865902426\n","\n"," Precision 0.8065824651977506\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [129/300], Loss: 0.3697\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.7176607044746963\n","\n"," Precision 0.8071219333577444\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [130/300], Loss: 0.3748\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.7175971731448764\n","\n"," Precision 0.8075026697870987\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [131/300], Loss: 0.4070\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.7175489921051577\n","\n"," Precision 0.8080602942503836\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [132/300], Loss: 0.2880\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7174872733057588\n","\n"," Precision 0.8085740537391032\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [133/300], Loss: 0.3140\n","Accuracy of the network: 80.68181818181819 %\n","\n"," Recall 0.7173080718373791\n","\n"," Precision 0.8090552933843825\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [134/300], Loss: 0.4257\n","Accuracy of the network: 82.07070707070707 %\n","\n"," Recall 0.7172184133202743\n","\n"," Precision 0.809650170271107\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [135/300], Loss: 0.3952\n","Accuracy of the network: 81.31313131313131 %\n","\n"," Recall 0.7171634680822104\n","\n"," Precision 0.8100990577434163\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [136/300], Loss: 0.3566\n","Accuracy of the network: 81.31313131313131 %\n","\n"," Recall 0.7170346637844515\n","\n"," Precision 0.81062622736199\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [137/300], Loss: 0.4091\n","Accuracy of the network: 80.68181818181819 %\n","\n"," Recall 0.7168039854378233\n","\n"," Precision 0.811092079873382\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [138/300], Loss: 0.2975\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.7165601460853687\n","\n"," Precision 0.8116301116042574\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [139/300], Loss: 0.3600\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7164601903610818\n","\n"," Precision 0.8120812552175868\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [140/300], Loss: 0.4576\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7162732267076669\n","\n"," Precision 0.8125970517538449\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [141/300], Loss: 0.3946\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.7160277772606259\n","\n"," Precision 0.81312501321381\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [142/300], Loss: 0.3271\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7159679089026915\n","\n"," Precision 0.8135910093477576\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [143/300], Loss: 0.2894\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.7159483075115647\n","\n"," Precision 0.8140680442496347\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [144/300], Loss: 0.4280\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.715686810682709\n","\n"," Precision 0.8145696738318533\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [145/300], Loss: 0.3853\n","Accuracy of the network: 82.57575757575758 %\n","\n"," Recall 0.7156305441905935\n","\n"," Precision 0.815169199678304\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [146/300], Loss: 0.3192\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7155108865675399\n","\n"," Precision 0.815642229099629\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [147/300], Loss: 0.3082\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.7154056322434329\n","\n"," Precision 0.8160097769630309\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [148/300], Loss: 0.2794\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.7152485854662197\n","\n"," Precision 0.8165104177212626\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [149/300], Loss: 0.3054\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.7150483640784396\n","\n"," Precision 0.8170233325951725\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [150/300], Loss: 0.2508\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.7147582296424634\n","\n"," Precision 0.8175430870548672\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [151/300], Loss: 0.3225\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.7146185004259166\n","\n"," Precision 0.8180497512437811\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [152/300], Loss: 0.4911\n","Accuracy of the network: 80.68181818181819 %\n","\n"," Recall 0.7142289691380412\n","\n"," Precision 0.8185902891866749\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [153/300], Loss: 0.2983\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7141190398572482\n","\n"," Precision 0.8190208193947026\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [154/300], Loss: 0.2957\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.7139423486695191\n","\n"," Precision 0.8195284218765287\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [155/300], Loss: 0.2580\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7137994106290011\n","\n"," Precision 0.8199964979863421\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [156/300], Loss: 0.3752\n","Accuracy of the network: 81.31313131313131 %\n","\n"," Recall 0.7135861883287339\n","\n"," Precision 0.8204895037244848\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [157/300], Loss: 0.2891\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.7132419327871593\n","\n"," Precision 0.8210127215689293\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [158/300], Loss: 0.4058\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.7131394015915472\n","\n"," Precision 0.8214873502506985\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [159/300], Loss: 0.4584\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7129956747119226\n","\n"," Precision 0.8218961711197381\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [160/300], Loss: 0.3266\n","Accuracy of the network: 82.07070707070707 %\n","\n"," Recall 0.712837339020589\n","\n"," Precision 0.8224215925652528\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [161/300], Loss: 0.2271\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7128067172087715\n","\n"," Precision 0.8227633708457225\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [162/300], Loss: 0.4631\n","Accuracy of the network: 80.55555555555556 %\n","\n"," Recall 0.7124779234246642\n","\n"," Precision 0.8232298648294455\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [163/300], Loss: 0.4291\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.712185381407108\n","\n"," Precision 0.8238362237579867\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [164/300], Loss: 0.4032\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7121112693865139\n","\n"," Precision 0.8242006594790856\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [165/300], Loss: 0.3156\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7118563179077647\n","\n"," Precision 0.8246807099021397\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [166/300], Loss: 0.3365\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.7116564417177914\n","\n"," Precision 0.8250930356193514\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [167/300], Loss: 0.3483\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.711434184675835\n","\n"," Precision 0.8254914833862202\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [168/300], Loss: 0.4469\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.711254843144607\n","\n"," Precision 0.8259134283951961\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [169/300], Loss: 0.2310\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.7110576176424911\n","\n"," Precision 0.8263098052662925\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [170/300], Loss: 0.3685\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.7109309865678555\n","\n"," Precision 0.8267114310849387\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [171/300], Loss: 0.2053\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.7107840127701375\n","\n"," Precision 0.8271532168756475\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [172/300], Loss: 0.2620\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.7106038179237941\n","\n"," Precision 0.8274636625324283\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [173/300], Loss: 0.2567\n","Accuracy of the network: 80.3030303030303 %\n","\n"," Recall 0.7102328756732155\n","\n"," Precision 0.8279100201605772\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [174/300], Loss: 0.2719\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7101119189115811\n","\n"," Precision 0.8282723434201267\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [175/300], Loss: 0.4927\n","Accuracy of the network: 80.17676767676768 %\n","\n"," Recall 0.7098530293941212\n","\n"," Precision 0.8286154438667437\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [176/300], Loss: 0.3474\n","Accuracy of the network: 80.68181818181819 %\n","\n"," Recall 0.7095374429632281\n","\n"," Precision 0.8290587866327491\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [177/300], Loss: 0.2622\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.7093928386092372\n","\n"," Precision 0.8294902912621359\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [178/300], Loss: 0.4484\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.7094053639620778\n","\n"," Precision 0.8297806291390728\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [179/300], Loss: 0.2201\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7092148669452386\n","\n"," Precision 0.8301783170576827\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [180/300], Loss: 0.2870\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7090702319681572\n","\n"," Precision 0.8305382881344354\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [181/300], Loss: 0.3600\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.709009975640877\n","\n"," Precision 0.8308243849395134\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [182/300], Loss: 0.2531\n","Accuracy of the network: 82.32323232323232 %\n","\n"," Recall 0.7089792210413993\n","\n"," Precision 0.8312116447735457\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [183/300], Loss: 0.4061\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.7088340742865338\n","\n"," Precision 0.8315444145356662\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [184/300], Loss: 0.4895\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.70860908261068\n","\n"," Precision 0.8319991961684027\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [185/300], Loss: 0.2828\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.7084450497226596\n","\n"," Precision 0.832330538842314\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [186/300], Loss: 0.3617\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7082910034992663\n","\n"," Precision 0.8327057379360682\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [187/300], Loss: 0.3506\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.7080543977095701\n","\n"," Precision 0.8330883931372711\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [188/300], Loss: 0.2302\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.7079878270095206\n","\n"," Precision 0.8334456294884225\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [189/300], Loss: 0.3084\n","Accuracy of the network: 80.55555555555556 %\n","\n"," Recall 0.7078704732281715\n","\n"," Precision 0.8336958477112532\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [190/300], Loss: 0.4708\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.7077681703914472\n","\n"," Precision 0.8340549514942379\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [191/300], Loss: 0.3896\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.7076686315731618\n","\n"," Precision 0.8343918086967792\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [192/300], Loss: 0.4198\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.7075137713746771\n","\n"," Precision 0.8346529065548658\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [193/300], Loss: 0.3092\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.7073933559063899\n","\n"," Precision 0.835034832578895\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [194/300], Loss: 0.2572\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.7073226823230205\n","\n"," Precision 0.8353864097525124\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [195/300], Loss: 0.4947\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.7071910203092825\n","\n"," Precision 0.835665892681065\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [196/300], Loss: 0.2348\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7070456858229339\n","\n"," Precision 0.8359983534924957\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [197/300], Loss: 0.3129\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7068540598148272\n","\n"," Precision 0.8363808322824716\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [198/300], Loss: 0.3336\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7067041327572038\n","\n"," Precision 0.8367282885031857\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [199/300], Loss: 0.2778\n","Accuracy of the network: 82.32323232323232 %\n","\n"," Recall 0.7066573470841137\n","\n"," Precision 0.8370774229831907\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [200/300], Loss: 0.3841\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.706399506619953\n","\n"," Precision 0.8374140559375292\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [201/300], Loss: 0.3151\n","Accuracy of the network: 82.07070707070707 %\n","\n"," Recall 0.7062149105627367\n","\n"," Precision 0.8378487228340846\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [202/300], Loss: 0.2756\n","Accuracy of the network: 81.31313131313131 %\n","\n"," Recall 0.706022969391467\n","\n"," Precision 0.8382151065044037\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [203/300], Loss: 0.3743\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.7058511738545868\n","\n"," Precision 0.8385912637463906\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [204/300], Loss: 0.2633\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.7057143592250495\n","\n"," Precision 0.8389484469864962\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [205/300], Loss: 0.3860\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.7056338569069472\n","\n"," Precision 0.8392764700508542\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [206/300], Loss: 0.3034\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7054612160664467\n","\n"," Precision 0.8396076231484149\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [207/300], Loss: 0.2648\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.7052902473345927\n","\n"," Precision 0.8399867133711801\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [208/300], Loss: 0.2681\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.7051713914436748\n","\n"," Precision 0.8403469998346188\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [209/300], Loss: 0.2240\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.7049569344348743\n","\n"," Precision 0.8406749715517757\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [210/300], Loss: 0.3759\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.7048319984005798\n","\n"," Precision 0.841029387645559\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [211/300], Loss: 0.3313\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7046884715831364\n","\n"," Precision 0.8413487950823323\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [212/300], Loss: 0.3679\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.7045550191855428\n","\n"," Precision 0.8416033356004377\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [213/300], Loss: 0.3417\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.7043894987125944\n","\n"," Precision 0.841950256961522\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [214/300], Loss: 0.3068\n","Accuracy of the network: 82.07070707070707 %\n","\n"," Recall 0.7043272473115643\n","\n"," Precision 0.8422657888176899\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [215/300], Loss: 0.2072\n","Accuracy of the network: 82.44949494949495 %\n","\n"," Recall 0.7042217421551755\n","\n"," Precision 0.8426410024242779\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [216/300], Loss: 0.2994\n","Accuracy of the network: 80.68181818181819 %\n","\n"," Recall 0.7039871710766091\n","\n"," Precision 0.8429535668567438\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [217/300], Loss: 0.3982\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.703810295415795\n","\n"," Precision 0.8432650932324944\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [218/300], Loss: 0.2840\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7037050411671241\n","\n"," Precision 0.8435078707778435\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [219/300], Loss: 0.2293\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7035852086179213\n","\n"," Precision 0.8437562868228193\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [220/300], Loss: 0.4649\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.7034806049906961\n","\n"," Precision 0.8440478575722014\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [221/300], Loss: 0.1976\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.7033734281677096\n","\n"," Precision 0.8443348489815699\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [222/300], Loss: 0.3808\n","Accuracy of the network: 81.31313131313131 %\n","\n"," Recall 0.7032352628281658\n","\n"," Precision 0.8446271135908684\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [223/300], Loss: 0.2525\n","Accuracy of the network: 82.1969696969697 %\n","\n"," Recall 0.7031619576601278\n","\n"," Precision 0.8449377828054299\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [224/300], Loss: 0.3831\n","Accuracy of the network: 82.1969696969697 %\n","\n"," Recall 0.7030658747173701\n","\n"," Precision 0.8452654262736095\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [225/300], Loss: 0.3896\n","Accuracy of the network: 82.44949494949495 %\n","\n"," Recall 0.7030125610851284\n","\n"," Precision 0.8455894730935414\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [226/300], Loss: 0.1876\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7029167247224931\n","\n"," Precision 0.8458572027385776\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [227/300], Loss: 0.3659\n","Accuracy of the network: 81.31313131313131 %\n","\n"," Recall 0.7027570660655453\n","\n"," Precision 0.8461549168348528\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [228/300], Loss: 0.2823\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7026218263011302\n","\n"," Precision 0.846442882298296\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [229/300], Loss: 0.3479\n","Accuracy of the network: 82.44949494949495 %\n","\n"," Recall 0.7025943071916395\n","\n"," Precision 0.8467381097055736\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [230/300], Loss: 0.3490\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7025019680323099\n","\n"," Precision 0.8469971663594597\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [231/300], Loss: 0.3524\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.702437749909124\n","\n"," Precision 0.8472678943330045\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [232/300], Loss: 0.2149\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.702309588979121\n","\n"," Precision 0.8475145360740316\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [233/300], Loss: 0.3394\n","Accuracy of the network: 82.32323232323232 %\n","\n"," Recall 0.7022501013559169\n","\n"," Precision 0.8478178110129164\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [234/300], Loss: 0.3893\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.7022023368992353\n","\n"," Precision 0.8480748655859369\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [235/300], Loss: 0.4157\n","Accuracy of the network: 82.70202020202021 %\n","\n"," Recall 0.7021404883931264\n","\n"," Precision 0.8484059417963006\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [236/300], Loss: 0.3782\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.7020346897931955\n","\n"," Precision 0.8486123244405618\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [237/300], Loss: 0.4983\n","Accuracy of the network: 82.32323232323232 %\n","\n"," Recall 0.7019773698545205\n","\n"," Precision 0.848906800198155\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [238/300], Loss: 0.2328\n","Accuracy of the network: 82.44949494949495 %\n","\n"," Recall 0.7019503213785652\n","\n"," Precision 0.8491804153273671\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [239/300], Loss: 0.2735\n","Accuracy of the network: 82.57575757575758 %\n","\n"," Recall 0.7019564358174871\n","\n"," Precision 0.8494353660156769\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [240/300], Loss: 0.2980\n","Accuracy of the network: 82.32323232323232 %\n","\n"," Recall 0.7018924858145561\n","\n"," Precision 0.8497346233769671\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [241/300], Loss: 0.3148\n","Accuracy of the network: 82.1969696969697 %\n","\n"," Recall 0.7018508437670115\n","\n"," Precision 0.8500019778220224\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [242/300], Loss: 0.2489\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.7017521033914477\n","\n"," Precision 0.8502108318993261\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [243/300], Loss: 0.2366\n","Accuracy of the network: 81.31313131313131 %\n","\n"," Recall 0.7016433800505323\n","\n"," Precision 0.8504495543718672\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [244/300], Loss: 0.2616\n","Accuracy of the network: 80.55555555555556 %\n","\n"," Recall 0.7015000806494973\n","\n"," Precision 0.8506454557308645\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [245/300], Loss: 0.5419\n","Accuracy of the network: 80.93434343434343 %\n","\n"," Recall 0.7013825674416613\n","\n"," Precision 0.8508567939407324\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [246/300], Loss: 0.2713\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.7012905290102389\n","\n"," Precision 0.8510613512813875\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [247/300], Loss: 0.3664\n","Accuracy of the network: 82.95454545454545 %\n","\n"," Recall 0.7012948387028244\n","\n"," Precision 0.8513475177304964\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [248/300], Loss: 0.3487\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.7012324781803756\n","\n"," Precision 0.8515963255604805\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [249/300], Loss: 0.2627\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7011390097674566\n","\n"," Precision 0.8518267236744412\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [250/300], Loss: 0.3065\n","Accuracy of the network: 82.32323232323232 %\n","\n"," Recall 0.7010914051841747\n","\n"," Precision 0.8520974962692754\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [251/300], Loss: 0.2539\n","Accuracy of the network: 82.07070707070707 %\n","\n"," Recall 0.7010306045655992\n","\n"," Precision 0.8523517226479597\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [252/300], Loss: 0.3145\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.7009463525345382\n","\n"," Precision 0.8525769279473218\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [253/300], Loss: 0.4705\n","Accuracy of the network: 82.32323232323232 %\n","\n"," Recall 0.7009115136934452\n","\n"," Precision 0.8528187140405774\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [254/300], Loss: 0.2781\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.7008356315784037\n","\n"," Precision 0.8530406467267629\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [255/300], Loss: 0.3750\n","Accuracy of the network: 80.68181818181819 %\n","\n"," Recall 0.7007284250380674\n","\n"," Precision 0.8532164108988413\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [256/300], Loss: 0.3190\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.7005954272010823\n","\n"," Precision 0.853468832320004\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [257/300], Loss: 0.3527\n","Accuracy of the network: 82.1969696969697 %\n","\n"," Recall 0.7005624917055443\n","\n"," Precision 0.8536934292040903\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [258/300], Loss: 0.3103\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7004586269664521\n","\n"," Precision 0.8538931657307202\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [259/300], Loss: 0.3697\n","Accuracy of the network: 82.57575757575758 %\n","\n"," Recall 0.7004051863857375\n","\n"," Precision 0.8541779908089143\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [260/300], Loss: 0.4474\n","Accuracy of the network: 82.32323232323232 %\n","\n"," Recall 0.7003975862277745\n","\n"," Precision 0.8543784928235555\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [261/300], Loss: 0.2592\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7002613590671491\n","\n"," Precision 0.8546121477555727\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [262/300], Loss: 0.2880\n","Accuracy of the network: 82.95454545454545 %\n","\n"," Recall 0.7002062846728485\n","\n"," Precision 0.8549211395036068\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [263/300], Loss: 0.2749\n","Accuracy of the network: 81.18686868686869 %\n","\n"," Recall 0.7001047433787221\n","\n"," Precision 0.8551272053806414\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [264/300], Loss: 0.2603\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.700021863571315\n","\n"," Precision 0.8553197173179202\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [265/300], Loss: 0.3082\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.6999356467501608\n","\n"," Precision 0.8555644302449414\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [266/300], Loss: 0.2654\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.6998007614463535\n","\n"," Precision 0.8557575172779794\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [267/300], Loss: 0.2231\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.6997356706987531\n","\n"," Precision 0.8559511503233406\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [268/300], Loss: 0.4244\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.6996348471350674\n","\n"," Precision 0.856087013811526\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [269/300], Loss: 0.2436\n","Accuracy of the network: 81.31313131313131 %\n","\n"," Recall 0.6995484204468979\n","\n"," Precision 0.8562730561226317\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [270/300], Loss: 0.4329\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.6994558351958021\n","\n"," Precision 0.8564476596149727\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [271/300], Loss: 0.2469\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.699348430132928\n","\n"," Precision 0.8566871049229711\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [272/300], Loss: 0.3048\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.6992765505932285\n","\n"," Precision 0.8569132022837149\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [273/300], Loss: 0.2690\n","Accuracy of the network: 80.42929292929293 %\n","\n"," Recall 0.6991734742912061\n","\n"," Precision 0.8570401960322322\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [274/300], Loss: 0.3626\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.6991152137275931\n","\n"," Precision 0.857216658252222\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [275/300], Loss: 0.3117\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.6990068025912816\n","\n"," Precision 0.857472232950622\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [276/300], Loss: 0.3415\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.6988839455471899\n","\n"," Precision 0.857721205898824\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [277/300], Loss: 0.3865\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.6987951807228916\n","\n"," Precision 0.8579402735138152\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [278/300], Loss: 0.3730\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.6987523122805693\n","\n"," Precision 0.8580915844739861\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [279/300], Loss: 0.2834\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.6986467551275661\n","\n"," Precision 0.858271719038817\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [280/300], Loss: 0.3538\n","Accuracy of the network: 82.44949494949495 %\n","\n"," Recall 0.698589701541489\n","\n"," Precision 0.8585050151433145\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [281/300], Loss: 0.3128\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.6984826555861618\n","\n"," Precision 0.8587204830618407\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [282/300], Loss: 0.2863\n","Accuracy of the network: 80.55555555555556 %\n","\n"," Recall 0.6982982405537929\n","\n"," Precision 0.8589331288554196\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [283/300], Loss: 0.2262\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.6982171167913666\n","\n"," Precision 0.8590739536634612\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [284/300], Loss: 0.2471\n","Accuracy of the network: 81.06060606060606 %\n","\n"," Recall 0.6980875831485588\n","\n"," Precision 0.8592726528384279\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [285/300], Loss: 0.3409\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.698007770064996\n","\n"," Precision 0.8594894234475253\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [286/300], Loss: 0.2940\n","Accuracy of the network: 82.1969696969697 %\n","\n"," Recall 0.697920202566949\n","\n"," Precision 0.8597292227018963\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [287/300], Loss: 0.2589\n","Accuracy of the network: 82.1969696969697 %\n","\n"," Recall 0.6978542891361388\n","\n"," Precision 0.8599529083063889\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [288/300], Loss: 0.4188\n","Accuracy of the network: 81.94444444444444 %\n","\n"," Recall 0.6977797213946666\n","\n"," Precision 0.8601639712488769\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [289/300], Loss: 0.2224\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.697666606137643\n","\n"," Precision 0.8603851752323368\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [290/300], Loss: 0.3660\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.697571524221422\n","\n"," Precision 0.8605920567945884\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [291/300], Loss: 0.3368\n","Accuracy of the network: 81.43939393939394 %\n","\n"," Recall 0.6974716416295468\n","\n"," Precision 0.8607849901514562\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [292/300], Loss: 0.2519\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.6973841467250164\n","\n"," Precision 0.8609893828283612\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [293/300], Loss: 0.3260\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.697326825773519\n","\n"," Precision 0.8611605711062695\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [294/300], Loss: 0.2239\n","Accuracy of the network: 82.1969696969697 %\n","\n"," Recall 0.6972350148156081\n","\n"," Precision 0.8613974925847108\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [295/300], Loss: 0.2327\n","Accuracy of the network: 81.81818181818181 %\n","\n"," Recall 0.6971616128372308\n","\n"," Precision 0.8615886905285375\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [296/300], Loss: 0.2321\n","Accuracy of the network: 81.56565656565657 %\n","\n"," Recall 0.6970736593884914\n","\n"," Precision 0.8617772127482355\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [297/300], Loss: 0.3459\n","Accuracy of the network: 82.1969696969697 %\n","\n"," Recall 0.6970093210231038\n","\n"," Precision 0.8619988855016881\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [298/300], Loss: 0.3027\n","Accuracy of the network: 81.6919191919192 %\n","\n"," Recall 0.6968979210876207\n","\n"," Precision 0.8622320027889141\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [299/300], Loss: 0.3808\n","Accuracy of the network: 82.1969696969697 %\n","\n"," Recall 0.6968029557082555\n","\n"," Precision 0.8624716220766666\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Epoch [300/300], Loss: 0.3899\n","Accuracy of the network: 80.8080808080808 %\n","\n"," Recall 0.6966937811598006\n","\n"," Precision 0.8626242716974594\n","maximum Accuracy :  82.95454545454545\n"]}]},{"cell_type":"markdown","source":["#Testing fully connected layers for the preprocessed data"],"metadata":{"id":"ccvhxCyWEgVU"}},{"cell_type":"code","source":["x = torch.from_numpy(x)\n","y = torch.from_numpy(y)\n","\n","xtest = torch.from_numpy(xtest)\n","ytest = torch.from_numpy(ytest)"],"metadata":{"id":"dgtrM847FM2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 36"],"metadata":{"id":"OQYopjJ3FM2z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_datasetTrain = TensorDataset(x,y) # create your datset\n","my_dataloaderTrain = DataLoader(my_datasetTrain, batch_size=batch_size,\n","                                          shuffle=True)"],"metadata":{"id":"LMVjjCpwFM2z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_datasetTest = TensorDataset(xtest,ytest) # create your datset\n","my_dataloaderTest = DataLoader(my_datasetTest, batch_size=batch_size,\n","                                          shuffle=True)"],"metadata":{"id":"smRqQQJsFM20"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BinaryClassifier(nn.Module):\n","    def __init__(self):\n","        super(BinaryClassifier, self).__init__()\n","        self.fc1 = nn.Linear(7, 32)\n","        self.fc2 = nn.Linear(32, 16)\n","        self.fc3 = nn.Linear(16, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return self.sigmoid(x)\n","\n"],"metadata":{"id":"ZounDVVpcQrr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# instantiate the model\n","model = BinaryClassifier()\n","\n","# define the loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay = 0.0001)"],"metadata":{"id":"_9-lg1TzEp98"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 600\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)"],"metadata":{"id":"x-dfxioLE-uj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BHo4rC4yH8Uv","outputId":"89c4b0ca-9c34-4d22-ce56-9d503b38f456"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BinaryClassifier(\n","  (fc1): Linear(in_features=7, out_features=32, bias=True)\n","  (fc2): Linear(in_features=32, out_features=16, bias=True)\n","  (fc3): Linear(in_features=16, out_features=1, bias=True)\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["sum([element.numel() for element in model.parameters()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1ykW0NrHyJr","outputId":"8ae22e8c-087f-4de7-bccd-225a662b51a7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["801"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["acc : 78.125% over 500 epochs, no regularization\n","\n","78.75% over 500 epochs with regularization 0.0001\n","\n","80.375% over 600 epochs"],"metadata":{"id":"TsMowkahIQYk"}},{"cell_type":"code","source":["scheduler = StepLR(optimizer, step_size=200, gamma=0.1, verbose=True) \n","\n","acc = []\n","for epoch in range(num_epochs):\n","    for i, (sigs, labels) in enumerate(my_dataloaderTrain):  \n","        # Move tensors to the configured device\n","        sigs = sigs.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(sigs.unsqueeze(1).float())\n","        # Convert output from sigmoid to binary classes\n","        predicted = (sigmoid(outputs) > 0.5).float()\n","        #print(outputs.squeeze(1).squeeze(1).shape)\n","        loss = criterion(outputs.squeeze(1).squeeze(1).float(), labels.float())\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    scheduler.step()\n","\n","    print ('Epoch [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, loss.item()))\n","            \n","    # Validation\n","\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for sigs, labels in (my_dataloaderTest):\n","            sigs = sigs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(sigs.float())\n","            # print(outputs)\n","            # break\n","            predicted = (outputs > 0.5).int()\n","            total += labels.size(0)\n","            correct += (predicted.squeeze(1) == labels).sum().item()\n","        acc.append(100 * correct / total)\n","        print('Accuracy of the network: {} %'.format(100 * correct / total)) \n","\n","print(\"maximum Accuracy : \", max(acc))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XIwU36WDE2uW","outputId":"3025cf1d-5b2c-425c-d9a5-395259dc9e00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0000e-02.\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [1/600], Loss: 0.6928\n","Accuracy of the network: 49.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [2/600], Loss: 0.6779\n","Accuracy of the network: 54.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [3/600], Loss: 0.6023\n","Accuracy of the network: 57.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [4/600], Loss: 0.6888\n","Accuracy of the network: 51.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [5/600], Loss: 0.7279\n","Accuracy of the network: 60.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [6/600], Loss: 0.6953\n","Accuracy of the network: 60.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [7/600], Loss: 0.6856\n","Accuracy of the network: 66.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [8/600], Loss: 0.5658\n","Accuracy of the network: 71.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [9/600], Loss: 0.5961\n","Accuracy of the network: 66.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [10/600], Loss: 0.6606\n","Accuracy of the network: 71.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [11/600], Loss: 0.6588\n","Accuracy of the network: 70.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [12/600], Loss: 0.5861\n","Accuracy of the network: 73.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [13/600], Loss: 0.5772\n","Accuracy of the network: 60.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [14/600], Loss: 0.5972\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [15/600], Loss: 0.4754\n","Accuracy of the network: 75.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [16/600], Loss: 0.5598\n","Accuracy of the network: 75.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [17/600], Loss: 0.6054\n","Accuracy of the network: 75.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [18/600], Loss: 0.3405\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [19/600], Loss: 0.7147\n","Accuracy of the network: 75.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [20/600], Loss: 0.4759\n","Accuracy of the network: 76.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [21/600], Loss: 0.3374\n","Accuracy of the network: 75.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [22/600], Loss: 0.5146\n","Accuracy of the network: 75.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [23/600], Loss: 0.4062\n","Accuracy of the network: 75.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [24/600], Loss: 0.6262\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [25/600], Loss: 0.3052\n","Accuracy of the network: 75.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [26/600], Loss: 0.3229\n","Accuracy of the network: 75.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [27/600], Loss: 0.4461\n","Accuracy of the network: 74.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [28/600], Loss: 0.3195\n","Accuracy of the network: 75.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [29/600], Loss: 0.7524\n","Accuracy of the network: 75.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [30/600], Loss: 0.3858\n","Accuracy of the network: 76.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [31/600], Loss: 0.4257\n","Accuracy of the network: 75.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [32/600], Loss: 0.4842\n","Accuracy of the network: 74.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [33/600], Loss: 0.6278\n","Accuracy of the network: 74.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [34/600], Loss: 0.4266\n","Accuracy of the network: 77.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [35/600], Loss: 0.4634\n","Accuracy of the network: 76.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [36/600], Loss: 0.3315\n","Accuracy of the network: 75.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [37/600], Loss: 0.6270\n","Accuracy of the network: 75.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [38/600], Loss: 0.5773\n","Accuracy of the network: 77.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [39/600], Loss: 0.5555\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [40/600], Loss: 0.4129\n","Accuracy of the network: 76.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [41/600], Loss: 0.4364\n","Accuracy of the network: 74.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [42/600], Loss: 0.5287\n","Accuracy of the network: 75.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [43/600], Loss: 0.6203\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [44/600], Loss: 0.5186\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [45/600], Loss: 0.5976\n","Accuracy of the network: 77.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [46/600], Loss: 0.5095\n","Accuracy of the network: 77.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [47/600], Loss: 0.3919\n","Accuracy of the network: 75.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [48/600], Loss: 0.6651\n","Accuracy of the network: 76.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [49/600], Loss: 0.3418\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [50/600], Loss: 0.3029\n","Accuracy of the network: 75.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [51/600], Loss: 0.5628\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [52/600], Loss: 0.5873\n","Accuracy of the network: 75.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [53/600], Loss: 0.6163\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [54/600], Loss: 0.3965\n","Accuracy of the network: 76.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [55/600], Loss: 0.3390\n","Accuracy of the network: 77.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [56/600], Loss: 0.2894\n","Accuracy of the network: 75.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [57/600], Loss: 0.4316\n","Accuracy of the network: 76.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [58/600], Loss: 0.5041\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [59/600], Loss: 0.3413\n","Accuracy of the network: 76.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [60/600], Loss: 0.2910\n","Accuracy of the network: 72.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [61/600], Loss: 0.1797\n","Accuracy of the network: 75.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [62/600], Loss: 0.4047\n","Accuracy of the network: 77.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [63/600], Loss: 0.4887\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [64/600], Loss: 0.5551\n","Accuracy of the network: 76.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [65/600], Loss: 0.4806\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [66/600], Loss: 0.4289\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [67/600], Loss: 0.4556\n","Accuracy of the network: 77.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [68/600], Loss: 0.4505\n","Accuracy of the network: 70.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [69/600], Loss: 0.5611\n","Accuracy of the network: 75.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [70/600], Loss: 0.3631\n","Accuracy of the network: 76.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [71/600], Loss: 0.3969\n","Accuracy of the network: 76.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [72/600], Loss: 0.4386\n","Accuracy of the network: 76.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [73/600], Loss: 0.5622\n","Accuracy of the network: 75.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [74/600], Loss: 0.2912\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [75/600], Loss: 0.4747\n","Accuracy of the network: 77.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [76/600], Loss: 0.6483\n","Accuracy of the network: 76.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [77/600], Loss: 0.6264\n","Accuracy of the network: 75.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [78/600], Loss: 0.4923\n","Accuracy of the network: 78.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [79/600], Loss: 0.4581\n","Accuracy of the network: 77.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [80/600], Loss: 0.3677\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [81/600], Loss: 0.5590\n","Accuracy of the network: 76.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [82/600], Loss: 0.4594\n","Accuracy of the network: 76.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [83/600], Loss: 0.1982\n","Accuracy of the network: 75.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [84/600], Loss: 0.5444\n","Accuracy of the network: 77.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [85/600], Loss: 0.6895\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [86/600], Loss: 0.3689\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [87/600], Loss: 0.3447\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [88/600], Loss: 0.6514\n","Accuracy of the network: 66.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [89/600], Loss: 0.2291\n","Accuracy of the network: 77.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [90/600], Loss: 0.5182\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [91/600], Loss: 0.5011\n","Accuracy of the network: 77.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [92/600], Loss: 0.5070\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [93/600], Loss: 0.5155\n","Accuracy of the network: 76.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [94/600], Loss: 0.3922\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [95/600], Loss: 0.5298\n","Accuracy of the network: 77.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [96/600], Loss: 0.4246\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [97/600], Loss: 0.5480\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [98/600], Loss: 0.4021\n","Accuracy of the network: 77.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [99/600], Loss: 0.4553\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [100/600], Loss: 0.4986\n","Accuracy of the network: 75.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [101/600], Loss: 0.5601\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [102/600], Loss: 0.5497\n","Accuracy of the network: 77.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [103/600], Loss: 0.3384\n","Accuracy of the network: 76.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [104/600], Loss: 0.5055\n","Accuracy of the network: 76.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [105/600], Loss: 0.4461\n","Accuracy of the network: 77.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [106/600], Loss: 0.6552\n","Accuracy of the network: 71.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [107/600], Loss: 0.2938\n","Accuracy of the network: 75.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [108/600], Loss: 0.4968\n","Accuracy of the network: 77.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [109/600], Loss: 0.5295\n","Accuracy of the network: 78.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [110/600], Loss: 0.6459\n","Accuracy of the network: 75.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [111/600], Loss: 0.3949\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [112/600], Loss: 0.2718\n","Accuracy of the network: 77.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [113/600], Loss: 0.3903\n","Accuracy of the network: 78.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [114/600], Loss: 0.3789\n","Accuracy of the network: 78.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [115/600], Loss: 0.5166\n","Accuracy of the network: 78.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [116/600], Loss: 0.4407\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [117/600], Loss: 0.6208\n","Accuracy of the network: 75.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [118/600], Loss: 0.4730\n","Accuracy of the network: 77.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [119/600], Loss: 0.3207\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [120/600], Loss: 0.4287\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [121/600], Loss: 0.4466\n","Accuracy of the network: 75.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [122/600], Loss: 0.4240\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [123/600], Loss: 0.2855\n","Accuracy of the network: 77.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [124/600], Loss: 0.5220\n","Accuracy of the network: 71.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [125/600], Loss: 0.4756\n","Accuracy of the network: 74.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [126/600], Loss: 0.3830\n","Accuracy of the network: 77.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [127/600], Loss: 0.4291\n","Accuracy of the network: 75.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [128/600], Loss: 0.2718\n","Accuracy of the network: 78.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [129/600], Loss: 0.2876\n","Accuracy of the network: 76.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [130/600], Loss: 0.2879\n","Accuracy of the network: 77.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [131/600], Loss: 0.4732\n","Accuracy of the network: 76.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [132/600], Loss: 0.4469\n","Accuracy of the network: 78.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [133/600], Loss: 0.4892\n","Accuracy of the network: 73.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [134/600], Loss: 0.3695\n","Accuracy of the network: 77.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [135/600], Loss: 0.3680\n","Accuracy of the network: 77.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [136/600], Loss: 0.2933\n","Accuracy of the network: 77.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [137/600], Loss: 0.4537\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [138/600], Loss: 0.4500\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [139/600], Loss: 0.3923\n","Accuracy of the network: 76.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [140/600], Loss: 0.3565\n","Accuracy of the network: 73.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [141/600], Loss: 0.4138\n","Accuracy of the network: 77.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [142/600], Loss: 0.3185\n","Accuracy of the network: 73.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [143/600], Loss: 0.4592\n","Accuracy of the network: 74.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [144/600], Loss: 0.4276\n","Accuracy of the network: 77.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [145/600], Loss: 0.5786\n","Accuracy of the network: 74.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [146/600], Loss: 0.3891\n","Accuracy of the network: 76.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [147/600], Loss: 0.4455\n","Accuracy of the network: 74.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [148/600], Loss: 0.4473\n","Accuracy of the network: 77.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [149/600], Loss: 0.5054\n","Accuracy of the network: 73.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [150/600], Loss: 0.4237\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [151/600], Loss: 0.3364\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [152/600], Loss: 0.3072\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [153/600], Loss: 0.5459\n","Accuracy of the network: 68.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [154/600], Loss: 0.3828\n","Accuracy of the network: 72.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [155/600], Loss: 0.6282\n","Accuracy of the network: 76.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [156/600], Loss: 0.6440\n","Accuracy of the network: 78.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [157/600], Loss: 0.5104\n","Accuracy of the network: 71.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [158/600], Loss: 0.4830\n","Accuracy of the network: 78.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [159/600], Loss: 0.4905\n","Accuracy of the network: 72.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [160/600], Loss: 0.4347\n","Accuracy of the network: 77.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [161/600], Loss: 0.3267\n","Accuracy of the network: 76.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [162/600], Loss: 0.4883\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [163/600], Loss: 0.3466\n","Accuracy of the network: 75.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [164/600], Loss: 0.3832\n","Accuracy of the network: 76.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [165/600], Loss: 0.4617\n","Accuracy of the network: 78.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [166/600], Loss: 0.3895\n","Accuracy of the network: 76.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [167/600], Loss: 0.5118\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [168/600], Loss: 0.2429\n","Accuracy of the network: 77.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [169/600], Loss: 0.4743\n","Accuracy of the network: 74.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [170/600], Loss: 0.4884\n","Accuracy of the network: 71.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [171/600], Loss: 0.2834\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [172/600], Loss: 0.4612\n","Accuracy of the network: 78.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [173/600], Loss: 0.3513\n","Accuracy of the network: 76.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [174/600], Loss: 0.3606\n","Accuracy of the network: 78.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [175/600], Loss: 0.3241\n","Accuracy of the network: 78.375 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [176/600], Loss: 0.4584\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [177/600], Loss: 0.3501\n","Accuracy of the network: 76.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [178/600], Loss: 0.4267\n","Accuracy of the network: 78.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [179/600], Loss: 0.4193\n","Accuracy of the network: 77.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [180/600], Loss: 0.4304\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [181/600], Loss: 0.3393\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [182/600], Loss: 0.4938\n","Accuracy of the network: 75.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [183/600], Loss: 0.5136\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [184/600], Loss: 0.3594\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [185/600], Loss: 0.4067\n","Accuracy of the network: 78.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [186/600], Loss: 0.3291\n","Accuracy of the network: 74.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [187/600], Loss: 0.4824\n","Accuracy of the network: 75.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [188/600], Loss: 0.4840\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [189/600], Loss: 0.4710\n","Accuracy of the network: 78.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [190/600], Loss: 0.4285\n","Accuracy of the network: 74.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [191/600], Loss: 0.5463\n","Accuracy of the network: 75.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [192/600], Loss: 0.4219\n","Accuracy of the network: 75.625 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [193/600], Loss: 0.3440\n","Accuracy of the network: 75.25 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [194/600], Loss: 0.2901\n","Accuracy of the network: 73.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [195/600], Loss: 0.4716\n","Accuracy of the network: 73.5 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [196/600], Loss: 0.4485\n","Accuracy of the network: 75.75 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [197/600], Loss: 0.3283\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [198/600], Loss: 0.4656\n","Accuracy of the network: 74.0 %\n","Adjusting learning rate of group 0 to 1.0000e-02.\n","Epoch [199/600], Loss: 0.5490\n","Accuracy of the network: 75.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [200/600], Loss: 0.9187\n","Accuracy of the network: 74.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [201/600], Loss: 0.4606\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [202/600], Loss: 0.2920\n","Accuracy of the network: 76.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [203/600], Loss: 0.2604\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [204/600], Loss: 0.5902\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [205/600], Loss: 0.5415\n","Accuracy of the network: 76.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [206/600], Loss: 0.5019\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [207/600], Loss: 0.3604\n","Accuracy of the network: 75.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [208/600], Loss: 0.4731\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [209/600], Loss: 0.2595\n","Accuracy of the network: 76.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [210/600], Loss: 0.6193\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [211/600], Loss: 0.4100\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [212/600], Loss: 0.4133\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [213/600], Loss: 0.3642\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [214/600], Loss: 0.4175\n","Accuracy of the network: 75.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [215/600], Loss: 0.3349\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [216/600], Loss: 0.4121\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [217/600], Loss: 0.5217\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [218/600], Loss: 0.4434\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [219/600], Loss: 0.3340\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [220/600], Loss: 0.5549\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [221/600], Loss: 0.3145\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [222/600], Loss: 0.5226\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [223/600], Loss: 0.3722\n","Accuracy of the network: 76.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [224/600], Loss: 0.5692\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [225/600], Loss: 0.3756\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [226/600], Loss: 0.3746\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [227/600], Loss: 0.4748\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [228/600], Loss: 0.5658\n","Accuracy of the network: 75.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [229/600], Loss: 0.3712\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [230/600], Loss: 0.6421\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [231/600], Loss: 0.3851\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [232/600], Loss: 0.6290\n","Accuracy of the network: 75.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [233/600], Loss: 0.3614\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [234/600], Loss: 0.3313\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [235/600], Loss: 0.4226\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [236/600], Loss: 0.5005\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [237/600], Loss: 0.4970\n","Accuracy of the network: 76.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [238/600], Loss: 0.3513\n","Accuracy of the network: 76.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [239/600], Loss: 0.4651\n","Accuracy of the network: 75.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [240/600], Loss: 0.4265\n","Accuracy of the network: 76.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [241/600], Loss: 0.4054\n","Accuracy of the network: 76.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [242/600], Loss: 0.3074\n","Accuracy of the network: 76.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [243/600], Loss: 0.4859\n","Accuracy of the network: 76.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [244/600], Loss: 0.4339\n","Accuracy of the network: 77.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [245/600], Loss: 0.3522\n","Accuracy of the network: 77.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [246/600], Loss: 0.4647\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [247/600], Loss: 0.3342\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [248/600], Loss: 0.4461\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [249/600], Loss: 0.3292\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [250/600], Loss: 0.3886\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [251/600], Loss: 0.3983\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [252/600], Loss: 0.2513\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [253/600], Loss: 0.3801\n","Accuracy of the network: 78.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [254/600], Loss: 0.4258\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [255/600], Loss: 0.3938\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [256/600], Loss: 0.3544\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [257/600], Loss: 0.2528\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [258/600], Loss: 0.5059\n","Accuracy of the network: 80.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [259/600], Loss: 0.3959\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [260/600], Loss: 0.4928\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [261/600], Loss: 0.4582\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [262/600], Loss: 0.4348\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [263/600], Loss: 0.1989\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [264/600], Loss: 0.2483\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [265/600], Loss: 0.5304\n","Accuracy of the network: 80.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [266/600], Loss: 0.2596\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [267/600], Loss: 0.3485\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [268/600], Loss: 0.3044\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [269/600], Loss: 0.6075\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [270/600], Loss: 0.5226\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [271/600], Loss: 0.5205\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [272/600], Loss: 0.4877\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [273/600], Loss: 0.5428\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [274/600], Loss: 0.1911\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [275/600], Loss: 0.2281\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [276/600], Loss: 0.3707\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [277/600], Loss: 0.3678\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [278/600], Loss: 0.5166\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [279/600], Loss: 0.3866\n","Accuracy of the network: 78.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [280/600], Loss: 0.3054\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [281/600], Loss: 0.3871\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [282/600], Loss: 0.3385\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [283/600], Loss: 0.3187\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [284/600], Loss: 0.3949\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [285/600], Loss: 0.2228\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [286/600], Loss: 0.4303\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [287/600], Loss: 0.2246\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [288/600], Loss: 0.4546\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [289/600], Loss: 0.1366\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [290/600], Loss: 0.3106\n","Accuracy of the network: 78.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [291/600], Loss: 0.3521\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [292/600], Loss: 0.4571\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [293/600], Loss: 0.3340\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [294/600], Loss: 0.3277\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [295/600], Loss: 0.3272\n","Accuracy of the network: 80.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [296/600], Loss: 0.2388\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [297/600], Loss: 0.4927\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [298/600], Loss: 0.3490\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [299/600], Loss: 0.4391\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [300/600], Loss: 0.4559\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [301/600], Loss: 0.2279\n","Accuracy of the network: 78.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [302/600], Loss: 0.5294\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [303/600], Loss: 0.5255\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [304/600], Loss: 0.4725\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [305/600], Loss: 0.3602\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [306/600], Loss: 0.7217\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [307/600], Loss: 0.3776\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [308/600], Loss: 0.3683\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [309/600], Loss: 0.3039\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [310/600], Loss: 0.2873\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [311/600], Loss: 0.3499\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [312/600], Loss: 0.3875\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [313/600], Loss: 0.1677\n","Accuracy of the network: 78.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [314/600], Loss: 0.4206\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [315/600], Loss: 0.3755\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [316/600], Loss: 0.2725\n","Accuracy of the network: 80.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [317/600], Loss: 0.2809\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [318/600], Loss: 0.3869\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [319/600], Loss: 0.2792\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [320/600], Loss: 0.5741\n","Accuracy of the network: 80.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [321/600], Loss: 0.4127\n","Accuracy of the network: 80.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [322/600], Loss: 0.5024\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [323/600], Loss: 0.3435\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [324/600], Loss: 0.6412\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [325/600], Loss: 0.5894\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [326/600], Loss: 0.1796\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [327/600], Loss: 0.3981\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [328/600], Loss: 0.3408\n","Accuracy of the network: 80.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [329/600], Loss: 0.5205\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [330/600], Loss: 0.3594\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [331/600], Loss: 0.3839\n","Accuracy of the network: 80.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [332/600], Loss: 0.6660\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [333/600], Loss: 0.3578\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [334/600], Loss: 0.5068\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [335/600], Loss: 0.4111\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [336/600], Loss: 0.1299\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [337/600], Loss: 0.3856\n","Accuracy of the network: 78.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [338/600], Loss: 0.4714\n","Accuracy of the network: 80.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [339/600], Loss: 0.3365\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [340/600], Loss: 0.5381\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [341/600], Loss: 0.3173\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [342/600], Loss: 0.3446\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [343/600], Loss: 0.3299\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [344/600], Loss: 0.3356\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [345/600], Loss: 0.3082\n","Accuracy of the network: 80.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [346/600], Loss: 0.2933\n","Accuracy of the network: 80.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [347/600], Loss: 0.3542\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [348/600], Loss: 0.2939\n","Accuracy of the network: 80.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [349/600], Loss: 0.4283\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [350/600], Loss: 0.4766\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [351/600], Loss: 0.2660\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [352/600], Loss: 0.4386\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [353/600], Loss: 0.4431\n","Accuracy of the network: 78.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [354/600], Loss: 0.3440\n","Accuracy of the network: 80.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [355/600], Loss: 0.3234\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [356/600], Loss: 0.4110\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [357/600], Loss: 0.5092\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [358/600], Loss: 0.4453\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [359/600], Loss: 0.3046\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [360/600], Loss: 0.3359\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [361/600], Loss: 0.2226\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [362/600], Loss: 0.5573\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [363/600], Loss: 0.3414\n","Accuracy of the network: 78.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [364/600], Loss: 0.2732\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [365/600], Loss: 0.3381\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [366/600], Loss: 0.2595\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [367/600], Loss: 0.2199\n","Accuracy of the network: 80.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [368/600], Loss: 0.5077\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [369/600], Loss: 0.2558\n","Accuracy of the network: 78.875 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [370/600], Loss: 0.2417\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [371/600], Loss: 0.2201\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [372/600], Loss: 0.6074\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [373/600], Loss: 0.3797\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [374/600], Loss: 0.3022\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [375/600], Loss: 0.1659\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [376/600], Loss: 0.3408\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [377/600], Loss: 0.3108\n","Accuracy of the network: 80.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [378/600], Loss: 0.2579\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [379/600], Loss: 0.2792\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [380/600], Loss: 0.3669\n","Accuracy of the network: 78.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [381/600], Loss: 0.5460\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [382/600], Loss: 0.3203\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [383/600], Loss: 0.2186\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [384/600], Loss: 0.2860\n","Accuracy of the network: 80.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [385/600], Loss: 0.5656\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [386/600], Loss: 0.4335\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [387/600], Loss: 0.3487\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [388/600], Loss: 0.4427\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [389/600], Loss: 0.3114\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [390/600], Loss: 0.4230\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [391/600], Loss: 0.6245\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [392/600], Loss: 0.3839\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [393/600], Loss: 0.2721\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [394/600], Loss: 0.3897\n","Accuracy of the network: 80.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [395/600], Loss: 0.4028\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [396/600], Loss: 0.5118\n","Accuracy of the network: 80.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [397/600], Loss: 0.4448\n","Accuracy of the network: 80.25 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [398/600], Loss: 0.4009\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch [399/600], Loss: 0.3206\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [400/600], Loss: 0.1667\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [401/600], Loss: 0.3041\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [402/600], Loss: 0.3810\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [403/600], Loss: 0.1710\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [404/600], Loss: 0.2485\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [405/600], Loss: 0.4512\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [406/600], Loss: 0.3751\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [407/600], Loss: 0.2964\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [408/600], Loss: 0.4072\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [409/600], Loss: 0.2522\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [410/600], Loss: 0.3706\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [411/600], Loss: 0.3574\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [412/600], Loss: 0.3546\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [413/600], Loss: 0.3158\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [414/600], Loss: 0.5084\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [415/600], Loss: 0.3645\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [416/600], Loss: 0.3753\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [417/600], Loss: 0.2579\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [418/600], Loss: 0.3767\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [419/600], Loss: 0.3460\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [420/600], Loss: 0.4947\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [421/600], Loss: 0.4339\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [422/600], Loss: 0.3766\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [423/600], Loss: 0.3130\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [424/600], Loss: 0.5222\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [425/600], Loss: 0.2953\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [426/600], Loss: 0.2144\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [427/600], Loss: 0.2361\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [428/600], Loss: 0.3049\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [429/600], Loss: 0.3566\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [430/600], Loss: 0.3306\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [431/600], Loss: 0.5425\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [432/600], Loss: 0.2554\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [433/600], Loss: 0.2418\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [434/600], Loss: 0.3769\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [435/600], Loss: 0.4993\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [436/600], Loss: 0.3571\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [437/600], Loss: 0.2996\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [438/600], Loss: 0.3137\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [439/600], Loss: 0.4321\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [440/600], Loss: 0.3833\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [441/600], Loss: 0.3220\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [442/600], Loss: 0.4171\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [443/600], Loss: 0.2994\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [444/600], Loss: 0.4401\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [445/600], Loss: 0.2824\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [446/600], Loss: 0.4055\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [447/600], Loss: 0.3835\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [448/600], Loss: 0.3837\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [449/600], Loss: 0.1881\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [450/600], Loss: 0.3197\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [451/600], Loss: 0.5295\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [452/600], Loss: 0.2913\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [453/600], Loss: 0.3186\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [454/600], Loss: 0.3399\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [455/600], Loss: 0.4451\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [456/600], Loss: 0.3777\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [457/600], Loss: 0.3964\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [458/600], Loss: 0.2936\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [459/600], Loss: 0.3617\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [460/600], Loss: 0.3158\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [461/600], Loss: 0.3009\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [462/600], Loss: 0.4892\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [463/600], Loss: 0.3928\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [464/600], Loss: 0.2607\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [465/600], Loss: 0.4241\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [466/600], Loss: 0.4648\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [467/600], Loss: 0.3972\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [468/600], Loss: 0.2898\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [469/600], Loss: 0.4698\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [470/600], Loss: 0.1682\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [471/600], Loss: 0.3594\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [472/600], Loss: 0.3143\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [473/600], Loss: 0.3261\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [474/600], Loss: 0.2844\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [475/600], Loss: 0.2965\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [476/600], Loss: 0.3223\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [477/600], Loss: 0.4195\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [478/600], Loss: 0.3980\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [479/600], Loss: 0.3396\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [480/600], Loss: 0.2368\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [481/600], Loss: 0.3348\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [482/600], Loss: 0.2463\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [483/600], Loss: 0.3566\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [484/600], Loss: 0.4281\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [485/600], Loss: 0.3193\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [486/600], Loss: 0.4627\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [487/600], Loss: 0.3118\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [488/600], Loss: 0.3322\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [489/600], Loss: 0.2215\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [490/600], Loss: 0.5960\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [491/600], Loss: 0.4166\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [492/600], Loss: 0.3180\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [493/600], Loss: 0.2743\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [494/600], Loss: 0.5551\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [495/600], Loss: 0.4549\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [496/600], Loss: 0.3420\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [497/600], Loss: 0.2567\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [498/600], Loss: 0.3588\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [499/600], Loss: 0.2418\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [500/600], Loss: 0.3849\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [501/600], Loss: 0.3686\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [502/600], Loss: 0.4095\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [503/600], Loss: 0.2452\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [504/600], Loss: 0.1985\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [505/600], Loss: 0.3624\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [506/600], Loss: 0.2795\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [507/600], Loss: 0.4733\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [508/600], Loss: 0.3484\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [509/600], Loss: 0.3257\n","Accuracy of the network: 79.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [510/600], Loss: 0.4400\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [511/600], Loss: 0.2059\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [512/600], Loss: 0.2954\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [513/600], Loss: 0.2507\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [514/600], Loss: 0.3000\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [515/600], Loss: 0.2717\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [516/600], Loss: 0.4038\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [517/600], Loss: 0.3808\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [518/600], Loss: 0.3040\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [519/600], Loss: 0.3891\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [520/600], Loss: 0.1578\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [521/600], Loss: 0.3751\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [522/600], Loss: 0.4590\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [523/600], Loss: 0.2166\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [524/600], Loss: 0.5471\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [525/600], Loss: 0.2210\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [526/600], Loss: 0.2980\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [527/600], Loss: 0.4468\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [528/600], Loss: 0.2422\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [529/600], Loss: 0.3461\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [530/600], Loss: 0.4415\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [531/600], Loss: 0.1975\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [532/600], Loss: 0.4887\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [533/600], Loss: 0.3084\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [534/600], Loss: 0.3434\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [535/600], Loss: 0.4474\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [536/600], Loss: 0.2189\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [537/600], Loss: 0.3525\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [538/600], Loss: 0.3499\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [539/600], Loss: 0.1839\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [540/600], Loss: 0.5501\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [541/600], Loss: 0.6517\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [542/600], Loss: 0.2205\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [543/600], Loss: 0.2164\n","Accuracy of the network: 79.25 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [544/600], Loss: 0.5216\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [545/600], Loss: 0.4271\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [546/600], Loss: 0.3458\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [547/600], Loss: 0.3282\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [548/600], Loss: 0.5046\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [549/600], Loss: 0.4217\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [550/600], Loss: 0.2355\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [551/600], Loss: 0.3233\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [552/600], Loss: 0.4839\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [553/600], Loss: 0.4377\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [554/600], Loss: 0.3082\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [555/600], Loss: 0.1950\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [556/600], Loss: 0.2923\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [557/600], Loss: 0.2740\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [558/600], Loss: 0.3429\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [559/600], Loss: 0.3823\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [560/600], Loss: 0.3161\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [561/600], Loss: 0.5094\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [562/600], Loss: 0.4888\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [563/600], Loss: 0.4587\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [564/600], Loss: 0.2733\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [565/600], Loss: 0.3240\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [566/600], Loss: 0.4308\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [567/600], Loss: 0.2762\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [568/600], Loss: 0.4260\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [569/600], Loss: 0.3778\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [570/600], Loss: 0.4375\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [571/600], Loss: 0.4978\n","Accuracy of the network: 80.0 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [572/600], Loss: 0.2736\n","Accuracy of the network: 79.125 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [573/600], Loss: 0.3617\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [574/600], Loss: 0.2796\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [575/600], Loss: 0.4226\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [576/600], Loss: 0.3064\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [577/600], Loss: 0.5005\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [578/600], Loss: 0.3293\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [579/600], Loss: 0.3345\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [580/600], Loss: 0.2749\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [581/600], Loss: 0.2972\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [582/600], Loss: 0.2755\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [583/600], Loss: 0.1965\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [584/600], Loss: 0.5265\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [585/600], Loss: 0.3150\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [586/600], Loss: 0.3448\n","Accuracy of the network: 79.375 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [587/600], Loss: 0.2576\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [588/600], Loss: 0.1626\n","Accuracy of the network: 79.875 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [589/600], Loss: 0.2562\n","Accuracy of the network: 79.75 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [590/600], Loss: 0.2326\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [591/600], Loss: 0.3644\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [592/600], Loss: 0.3993\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [593/600], Loss: 0.2910\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [594/600], Loss: 0.4913\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [595/600], Loss: 0.1618\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [596/600], Loss: 0.2975\n","Accuracy of the network: 79.625 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [597/600], Loss: 0.3861\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [598/600], Loss: 0.3348\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Epoch [599/600], Loss: 0.3231\n","Accuracy of the network: 79.5 %\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Epoch [600/600], Loss: 0.4320\n","Accuracy of the network: 79.625 %\n","maximum Accuracy :  80.375\n"]}]},{"cell_type":"markdown","source":["#Testing only with date difference, frequency, power, width "],"metadata":{"id":"IDQjEN7gbIkD"}},{"cell_type":"code","source":["mean_tensor = torch.tensor([0.0871414782687525, 1.9893857392132595, -154.90684374070747, 5.875007060286158], dtype=torch.float32)\n","std_tensor = torch.tensor([0.0845755502639984, 0.8923242781137891, 19.407849095325062, 8.705384067948797], dtype=torch.float32)"],"metadata":{"id":"SOA1FWB-bbQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"NFVtfMXNiHna"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_labels = list(dict_labels.values())\n","list_test_labels = list(test_labels.values())"],"metadata":{"id":"IWPxzVlMiHnc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lastTrain = [(torch.from_numpy(item).unsqueeze(0)- mean_tensor.unsqueeze(1)) / std_tensor.unsqueeze(1)  for item in trainListBrutNew]\n"],"metadata":{"id":"qXjPZL0-iHnd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","lastTrain = [torch.from_numpy(item)   for item in trainListBrutNew]\n"],"metadata":{"id":"U2fmeMaPiHnd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lastTest = [torch.from_numpy(item)  for item in testListBrutNew]\n"],"metadata":{"id":"_FIxB-yYqtFT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Create a 1D adaptive max pooling layer\n","adaptive_max_pool = torch.nn.AdaptiveMaxPool1d(output_size=1600)\n","\n","# Apply the pooling layer to the list of signals\n","pooled_signals_Train = [adaptive_max_pool(sig) for sig in lastTrain]\n","pooled_signals_Test = [adaptive_max_pool(sig) for sig in lastTest]\n","\n","# The output will be a list of tensors of size (batch_size, num_channels, output_size)"],"metadata":{"id":"4l895wQZiHne"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","list_labels = [i.replace('nonmenace', \"0\") for i in list_labels]\n","list_labels = [i.replace('menace', \"1\") for i in list_labels]\n","list_labels  = list(map(int, list_labels ))"],"metadata":{"id":"C4WNlt6xo5Xd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_labelsTest = [i.replace('nonmenace', \"0\") for i in list_test_labels]\n","list_labelsTest = [i.replace('menace', \"1\") for i in list_labelsTest]\n","list_labelsTest  = list(map(int, list_labelsTest ))"],"metadata":{"id":"ujEiiwX3o5Xh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_labels_train_tensor = torch.tensor(list_labels)"],"metadata":{"id":"v8UMk7aCoYVJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_labels_test_tensor = torch.tensor(list_labelsTest)"],"metadata":{"id":"pO_YMOl7oYVK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 126"],"metadata":{"id":"YdYC2hxKpQMA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","signals_train_tensor = torch.stack(pooled_signals_Train)\n","\n","\n","my_datasetTrain_pool= TensorDataset(signals_train_tensor, list_labels_train_tensor) # create your datset\n","my_dataloaderTrain_pool = DataLoader(my_datasetTrain_pool, batch_size=batch_size,\n","                                          shuffle=True, drop_last = True)\n","\n","signals_test_tensor = torch.stack(pooled_signals_Test)\n","\n","my_datasetTest_pool = TensorDataset(signals_test_tensor,list_labels_test_tensor) # create your datset\n","my_dataloaderTest_pool = DataLoader(my_datasetTest_pool, batch_size=batch_size,\n","                                          shuffle=True, drop_last = True)"],"metadata":{"id":"UQDxEQEUiHnf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["number parameters : 152000"],"metadata":{"id":"IuDQnlHyqeU5"}},{"cell_type":"code","source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv1d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n","                        nn.BatchNorm1d(out_channels),\n","                        nn.ReLU())\n","        self.conv2 = nn.Sequential(\n","                        nn.Conv1d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n","                        nn.BatchNorm1d(out_channels))\n","        self.downsample = downsample\n","        self.relu = nn.ReLU()\n","        self.out_channels = out_channels\n","        \n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, layers, num_classes = 1):\n","        super(ResNet, self).__init__()\n","        self.inplanes = 64\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv1d(4, 64, kernel_size = 7, stride = 2, padding = 3),\n","                        nn.BatchNorm1d(64),\n","                        nn.ReLU())\n","        self.maxpool = nn.MaxPool1d(kernel_size = 3, stride = 2, padding = 1)\n","        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n","        #self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n","        #self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n","        #self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n","        self.avgpool = nn.AvgPool1d(7, stride=1)\n","        #self.fc = nn.Linear(in_features=319872, out_features=1, bias=False)\n","        #self.fc = nn.Linear(in_features=26816, out_features=1, bias=False)\n","        self.fc = nn.Linear(in_features=25216, out_features=1, bias=False)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes:\n","            \n","            downsample = nn.Sequential(\n","                nn.Conv1d(self.inplanes, planes, kernel_size=1, stride=stride),\n","                nn.BatchNorm1d(planes),\n","            )\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","    \n","    \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.maxpool(x)\n","        x = self.layer0(x)\n","        #x = self.layer1(x)\n","        # x = self.layer2(x)\n","        # x = self.layer3(x)\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        #x = x.view(-1,x.shape[1]*x.shape[2]) \n","        #print(x.shape)\n","        x = self.fc(x)\n","\n","        return x"],"metadata":{"id":"AYCSOaCql2ZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n"],"metadata":{"id":"IoG18rOUl2Zb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model = ResNet(ResidualBlock, [5]).to(device)"],"metadata":{"id":"tAvmx2H9l2Zc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sum([element.numel() for element in model.parameters()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ysQ02jHkqaA3","outputId":"8a931c83-1305-4b07-e7a9-81f8d36a778b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["152000"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["num_epochs = 50\n"],"metadata":{"id":"hRncaVVUl2Zf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["80% sur 50 epochs\n","80.25% sans normaliser les donnees"],"metadata":{"id":"Qyppxw4AqRYk"}},{"cell_type":"code","source":["yTrue = []\n","yPred = []\n","from sklearn.metrics import recall_score, precision_score\n","from torch.optim.lr_scheduler import StepLR\n","# Loss and optimizer\n","lossFun = torch.nn.BCEWithLogitsLoss()\n","sigmoid = nn.Sigmoid()\n","#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9) \n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","#scheduler = StepLR(optimizer, step_size=50, gamma=0.1, verbose=True) \n","\n","# Train the model\n","total_step = len(my_dataloaderTrain_pool)\n","\n","acc = []\n","for epoch in range(num_epochs):\n","    for i, (sigs, labels) in enumerate(my_dataloaderTrain_pool):  \n","        # Move tensors to the configured device\n","        sigs = sigs.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(sigs.squeeze(1).float())\n","        # Convert output from sigmoid to binary classes\n","        predicted = (sigmoid(outputs) > 0.5).float()\n","        loss = lossFun(outputs.squeeze(1).float(), labels.float())\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    #scheduler.step()\n","\n","    print ('Epoch [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, loss.item()))\n","            \n","    # Validation\n","\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for sigs, labels in (my_dataloaderTest_pool):\n","            sigs = sigs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(sigs.squeeze(1).float())\n","            predicted = (sigmoid(outputs) > 0.5).int()\n","            total += labels.size(0)\n","            correct += (predicted.squeeze(1) == labels).sum().item()\n","            yTrue.append(labels.int().cpu())\n","            yPred.append(predicted.squeeze(1).cpu())\n","        acc.append(100 * correct / total)\n","        print('Accuracy of the network: {} %'.format(100 * correct / total)) \n","        print('\\n Recall', recall_score(np.array(torch.stack(yTrue, dim=0).cpu()),np.array(torch.stack(yPred, dim=0).cpu()),average='micro'))\n","        print('\\n Precision', precision_score(np.array(torch.stack(yTrue).squeeze(1).cpu()),np.array(torch.stack(yPred).squeeze(1).cpu()),average='micro'))\n","\n","print(\"maximum Accuracy : \", max(acc))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a7f665e9-046b-489b-9faa-444652d7737a","id":"A-nTfA59l2Zf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Loss: 1.2482\n","Accuracy of the network: 73.41269841269842 %\n","\n"," Recall 0.5883977900552486\n","\n"," Precision 0.8037735849056604\n","Epoch [2/50], Loss: 0.3681\n","Accuracy of the network: 75.26455026455027 %\n","\n"," Recall 0.7075862068965517\n","\n"," Precision 0.7445573294629898\n","Epoch [3/50], Loss: 0.3788\n","Accuracy of the network: 78.43915343915344 %\n","\n"," Recall 0.7170506912442396\n","\n"," Precision 0.761252446183953\n","Epoch [4/50], Loss: 0.4482\n","Accuracy of the network: 79.23280423280423 %\n","\n"," Recall 0.7570738440303658\n","\n"," Precision 0.7549896765313145\n","Epoch [5/50], Loss: 0.3085\n","Accuracy of the network: 75.92592592592592 %\n","\n"," Recall 0.7920353982300885\n","\n"," Precision 0.7358684480986639\n","Epoch [6/50], Loss: 0.3331\n","Accuracy of the network: 79.8941798941799 %\n","\n"," Recall 0.7981609195402298\n","\n"," Precision 0.7421975203078238\n","Epoch [7/50], Loss: 0.2851\n","Accuracy of the network: 77.38095238095238 %\n","\n"," Recall 0.7794001578531965\n","\n"," Precision 0.7512362114872575\n","Epoch [8/50], Loss: 0.2970\n","Accuracy of the network: 78.70370370370371 %\n","\n"," Recall 0.7931629834254144\n","\n"," Precision 0.7477213541666666\n","Epoch [9/50], Loss: 0.4303\n","Accuracy of the network: 76.98412698412699 %\n","\n"," Recall 0.8112338858195212\n","\n"," Precision 0.7390939597315436\n","Epoch [10/50], Loss: 0.3566\n","Accuracy of the network: 79.36507936507937 %\n","\n"," Recall 0.8192604856512141\n","\n"," Precision 0.7389248382279742\n","Epoch [11/50], Loss: 0.2796\n","Accuracy of the network: 80.42328042328042 %\n","\n"," Recall 0.8248431618569636\n","\n"," Precision 0.740148615176762\n","Epoch [12/50], Loss: 0.2204\n","Accuracy of the network: 79.4973544973545 %\n","\n"," Recall 0.8285780027611597\n","\n"," Precision 0.7404894098293234\n","Epoch [13/50], Loss: 0.2060\n","Accuracy of the network: 79.76190476190476 %\n","\n"," Recall 0.82474008062805\n","\n"," Precision 0.7444933920704846\n","Epoch [14/50], Loss: 0.2051\n","Accuracy of the network: 79.76190476190476 %\n","\n"," Recall 0.8283802401102145\n","\n"," Precision 0.7449557522123894\n","Epoch [15/50], Loss: 0.1626\n","Accuracy of the network: 80.15873015873017 %\n","\n"," Recall 0.828434974283615\n","\n"," Precision 0.7468123861566485\n","Epoch [16/50], Loss: 0.2456\n","Accuracy of the network: 77.11640211640211 %\n","\n"," Recall 0.8180722891566266\n","\n"," Precision 0.7506317119393556\n","Epoch [17/50], Loss: 0.2947\n","Accuracy of the network: 78.96825396825396 %\n","\n"," Recall 0.8123380829015544\n","\n"," Precision 0.7540958965880055\n","Epoch [18/50], Loss: 0.2029\n","Accuracy of the network: 79.4973544973545 %\n","\n"," Recall 0.8132170720513997\n","\n"," Precision 0.7545777146912704\n","Epoch [19/50], Loss: 0.2565\n","Accuracy of the network: 78.04232804232804 %\n","\n"," Recall 0.8108969714534126\n","\n"," Precision 0.7555015525853922\n","Epoch [20/50], Loss: 0.1670\n","Accuracy of the network: 79.4973544973545 %\n","\n"," Recall 0.8138510257469366\n","\n"," Precision 0.7549169859514687\n","Epoch [21/50], Loss: 0.2186\n","Accuracy of the network: 80.15873015873017 %\n","\n"," Recall 0.8175498426023085\n","\n"," Precision 0.7543265157932955\n","Epoch [22/50], Loss: 0.1848\n","Accuracy of the network: 79.4973544973545 %\n","\n"," Recall 0.8203427999499562\n","\n"," Precision 0.7539381395883638\n","Epoch [23/50], Loss: 0.1839\n","Accuracy of the network: 78.3068783068783 %\n","\n"," Recall 0.8191387559808613\n","\n"," Precision 0.754517408550022\n","Epoch [24/50], Loss: 0.0754\n","Accuracy of the network: 77.38095238095238 %\n","\n"," Recall 0.8183694530443757\n","\n"," Precision 0.7541208791208791\n","Epoch [25/50], Loss: 0.0643\n","Accuracy of the network: 78.57142857142857 %\n","\n"," Recall 0.8157691884153727\n","\n"," Precision 0.7553017944535073\n","Epoch [26/50], Loss: 0.1082\n","Accuracy of the network: 79.8941798941799 %\n","\n"," Recall 0.8167566995021713\n","\n"," Precision 0.755535959239663\n","Epoch [27/50], Loss: 0.0514\n","Accuracy of the network: 77.77777777777777 %\n","\n"," Recall 0.8166428717111972\n","\n"," Precision 0.755257945864378\n","Epoch [28/50], Loss: 0.0581\n","Accuracy of the network: 76.98412698412699 %\n","\n"," Recall 0.8167158308751229\n","\n"," Precision 0.7544736124988646\n","Epoch [29/50], Loss: 0.1683\n","Accuracy of the network: 78.70370370370371 %\n","\n"," Recall 0.8190015186028854\n","\n"," Precision 0.7536244541484716\n","Epoch [30/50], Loss: 0.1028\n","Accuracy of the network: 77.64550264550265 %\n","\n"," Recall 0.8194329755023396\n","\n"," Precision 0.753035413153457\n","Epoch [31/50], Loss: 0.0742\n","Accuracy of the network: 78.43915343915344 %\n","\n"," Recall 0.8161960575386255\n","\n"," Precision 0.7545559021507142\n","Epoch [32/50], Loss: 0.0626\n","Accuracy of the network: 79.23280423280423 %\n","\n"," Recall 0.8142734307824592\n","\n"," Precision 0.7559671110401532\n","Epoch [33/50], Loss: 0.0916\n","Accuracy of the network: 77.51322751322752 %\n","\n"," Recall 0.8142463925264826\n","\n"," Precision 0.7554558117938399\n","Epoch [34/50], Loss: 0.0210\n","Accuracy of the network: 78.70370370370371 %\n","\n"," Recall 0.8124797669148591\n","\n"," Precision 0.7565184626978146\n","Epoch [35/50], Loss: 0.0093\n","Accuracy of the network: 79.23280423280423 %\n","\n"," Recall 0.8116055983645227\n","\n"," Precision 0.7572445161763627\n","Epoch [36/50], Loss: 0.0247\n","Accuracy of the network: 80.42328042328042 %\n","\n"," Recall 0.8106992739778373\n","\n"," Precision 0.7585812356979404\n","Epoch [37/50], Loss: 0.0059\n","Accuracy of the network: 76.85185185185185 %\n","\n"," Recall 0.8108409547178229\n","\n"," Precision 0.7578705955938564\n","Epoch [38/50], Loss: 0.0132\n","Accuracy of the network: 78.57142857142857 %\n","\n"," Recall 0.8114368440101339\n","\n"," Precision 0.757688408246029\n","Epoch [39/50], Loss: 0.0588\n","Accuracy of the network: 78.04232804232804 %\n","\n"," Recall 0.8080558690744921\n","\n"," Precision 0.7591119946984758\n","Epoch [40/50], Loss: 0.0398\n","Accuracy of the network: 77.77777777777777 %\n","\n"," Recall 0.8040159537890249\n","\n"," Precision 0.7609006898346999\n","Epoch [41/50], Loss: 0.1313\n","Accuracy of the network: 78.43915343915344 %\n","\n"," Recall 0.8025088884416717\n","\n"," Precision 0.7616834330828982\n","Epoch [42/50], Loss: 0.0333\n","Accuracy of the network: 78.04232804232804 %\n","\n"," Recall 0.8030124426981009\n","\n"," Precision 0.7612839138262867\n","Epoch [43/50], Loss: 0.0845\n","Accuracy of the network: 80.02645502645503 %\n","\n"," Recall 0.8026736599718562\n","\n"," Precision 0.7620233179499636\n","Epoch [44/50], Loss: 0.0194\n","Accuracy of the network: 77.38095238095238 %\n","\n"," Recall 0.805\n","\n"," Precision 0.7605550634780042\n","Epoch [45/50], Loss: 0.1194\n","Accuracy of the network: 77.64550264550265 %\n","\n"," Recall 0.802248151994624\n","\n"," Precision 0.7617611230349788\n","Epoch [46/50], Loss: 0.0126\n","Accuracy of the network: 78.70370370370371 %\n","\n"," Recall 0.8009441854906179\n","\n"," Precision 0.7625305797348808\n","Epoch [47/50], Loss: 0.0159\n","Accuracy of the network: 76.32275132275132 %\n","\n"," Recall 0.8005382950090691\n","\n"," Precision 0.7619312802806705\n","Epoch [48/50], Loss: 0.0092\n","Accuracy of the network: 76.32275132275132 %\n","\n"," Recall 0.8018565207426083\n","\n"," Precision 0.7605848143920865\n","Epoch [49/50], Loss: 0.0122\n","Accuracy of the network: 75.13227513227513 %\n","\n"," Recall 0.8034571781344707\n","\n"," Precision 0.7588656241717466\n","Epoch [50/50], Loss: 0.0175\n","Accuracy of the network: 78.70370370370371 %\n","\n"," Recall 0.8049826761260518\n","\n"," Precision 0.7582759156607781\n","maximum Accuracy :  80.42328042328042\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"MO5ABEvxpUCx"},"execution_count":null,"outputs":[]}]}